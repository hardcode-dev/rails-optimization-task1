# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.
Необходимо было обработать файл с данными, чуть больше ста мегабайт.
У нас уже была программа на `ruby`, которая умела делать нужную обработку.
Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было 
понятно, закончит ли она вообще работу за какое-то разумное время.
Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал 
использовать такую метрику: времени выполнения отчета в мс.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы
при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне
получать обратную связь по эффективности сделанных изменений за небольшое время на файлах разгоного объема.

Вот как я построил `feedback_loop`:
- профилировать метод `work` разными профилировщиками
- найти главную точку роста
- оптимизировать ее
- проверить тестом, что ничего не сломал
- замерить время
- закоммитить изменения

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался:
1. Выполнил `rubocop --require rubocop-performance ./task-1.rb -a`
2. Написал скрипт `analyzers/demo_data/generate_data.rb` для генерации демо данных с разным количеством строк
    - в `LINE_COUNTS` указываем массив с нужным количеством строк
    - в `DATA_LARGE_PATH` указываем путь до файла data_large.txt
    - выполняем `ruby analyzers/demo_data/generate_data.rb`
3. Использовал профилировщики:
   - rbspy
   - ruby-prof
   - stackprof

Вот какие проблемы удалось найти и решить:

### Ваша находка №1
- Запустил `ruby_prof#flat` для 10000, 20000, 30000 строк:
   ```
   10000 lines - 2.549670  sec.
   20000 lines - 10.241034 sec.
   30000 lines - 27.364214 sec.
   ```
- главная точка роста `Array#select`
- сделал группировку по id пользователя 
  ```
  sessions_by_user_id = sessions.group_by { |f| f['user_id'] }

  users_objects = users.map do |user|
    User.new(attributes: user, sessions: sessions_by_user_id[user['id']])
  end
  ```
- как изменилась метрика
  ```
   10000 lines - 0.361118 sec.
   20000 lines - 0.568627 sec.
   30000 lines - 1.077505 sec.
   ```
- исправленная проблема перестала быть главной точкой роста

### Ваша находка №2
- отчет `ruby_prof#graph` показал точку роста в `uniqueBrowsers += [browser] if uniqueBrowsers.all? { |b| b != browser }`
- переделал unique_browsers в `hash` и взял ключи
- как изменилась метрика
    ```
   10000 lines - 0.247521 sec.
   20000 lines - 0.346533 sec.
   30000 lines - 0.994447 sec.
   ```
- исправленная проблема перестала быть главной точкой роста

### Ваша находка №3
- отчет `ruby_prof#graph` показал точку роста в `#collect_stats_from_users`
- рефакторинг: вызов один раз, а не 7
- как изменилась метрика
    ```
   10000 lines - 0.061915 sec.
   20000 lines - 0.129759 sec.
   30000 lines - 0.177151 sec.
   ```
- исправленная проблема перестала быть главной точкой роста

### Ваша находка №4
- отчет `ruby_prof#graph` показал точку роста в `#parse_session`
- небольшой рефакторинг: убрал лишние поля, добавил гем `oj`, отключил GC для тестов
- как изменилась метрика
    ```
   10000 lines - 0.073147 sec.
   20000 lines - 0.114015 sec.
   30000 lines - 0.169559 sec.
   3250940 lines- 19.238135 sec.
   ```
- исправленная проблема перестала быть главной точкой роста

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с `2.549670` до `0.073147` за `10000` строк, а весь файл за `19.238135` и уложиться
в заданный бюджет.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы я написал тест `analyzers/benchmark.rb`.