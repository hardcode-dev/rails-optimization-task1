# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: файл должен обрабатываться не больше 30 секунд

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`:

Выбрал для работы версию ruby-3.1.3
Сначала я распаковал архив data_large.txt.gz. Попробовал запустить программу на нем и увидел, что она не выполняется.
При запуске теста на тестовых данных размером 18 строчек программа показала время в диапазоне 0.001-0.0005 секунды.
Тогда я решил достать из data_large.txt образец данных размером 100 строк кода с помощью команды `head -n 100 data_large.txt > sample100.txt`, после чего создал файл test.rb, куда импортировал tast-1.rb, предварительно отключив в нем автопрогон тестов и изменив интерфейс метода #work, чтобы он принимал в качестве параметра файл с данными.
В новом файле импортировал библиотеку `require 'benchmark'` и замерил время выполнения для sample100.txt. Сделав аналогичные операции для 1000, 10000 и 100000 строк кода получил следующие результаты
```ruby
require_relative 'task-1.rb'

require 'benchmark'

Benchmark.bm do |x|
  x.report { work('sample100.txt') }
  x.report { work('sample1000.txt') }
  x.report { work('sample10000.txt') }
  x.report { work('sample100000.txt') }
end
```

```
       user     system      total        real
   0.002126   0.000916   0.003042 (  0.004293)
   0.043338   0.002797   0.046135 (  0.047601)
   2.070591   0.181741   2.252332 (  2.274877)
 282.355822  14.876178 297.232000 (301.957667)
```
Вычислив общее количество строк в `wc -l data_large.txt` и получив результат 3250940 можно предположить, что при росте данных в 10 раз мы получаем увеличение времени выполнения в 2^n * 10^(n-1) * 0.01 секунды где n- порядок числа строк, таким образом на 3M строках данных ожидаемый результат должен составить 64000 секунд, что является для нас неприемлемым результатом.
Следующим шагом я написал тест-кейс производительности с помощью фреймворка тестирования rspec и его расширения rspec-perfomance и добавил тест-кейс, проверяющий корректность работы данных на выборке в 100 строк
В результате мы получаем время, необходимое для feedback_loop в районе 5 секунд
```
...*.

Pending: (Failures listed here are expected and do not affect your suite's status)

  1) Perfomance works under 4s for 10000 strings of data
     # Temporarily skipped with xit
     # ./spec/performance_spec.rb:52


Finished in 4.12 seconds (files took 0.27141 seconds to load)
5 examples, 0 failures, 1 pending
```


## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я решил начать с инструмента rbspy
Устанавливаем `brew install rbspy`
Делаем наш test.rb исполняемым `chmod +x test.rb` и запускаем скрипт `sudo rbspy record bundle exec ruby test.rb`

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

### Ваша находка №2
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

### Ваша находка №X
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*

