# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: *тут ваша метрика*
  время выполнения метода work и его ips.
  Изначально эти параметры составляли:
  
    время выполнения: 2.09 секунды
    ips: 0.474  (±15.1%)

## Гарантия корректности работы оптимизированной программы
  Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.
  Кроме того, я добавил к этому тесту анализ асимптотики с проверкой на то, что алгоритм будет сохранять линейную прогрессию.
## Feedback-Loop
  Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь  получать эффективности сделанных изменений за *время, которое у вас получилось*

  Вот как я построил `feedback_loop`: 
  написал файл performance_evaluation.rb, с оценкой бенчмаркинга

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался профилайзерами `callgrind`, `stackprof_profilizer` и `graph_profilizer`, но потом главным образом пользовался `callgrind`, как наиболее удобным. 

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- какой отчёт показал главную точку роста
  отчет callgrind.callgrind.out.13832 показал, что самая большая нагрузка сосредоточена в парсинге даты (27.04% на собственное выполнение, 791 ms)
- как вы решили её оптимизировать
  при этом, с помощью byebug стало ясно, что без потери корректности результата от этого парсинга можно было вообще отказаться
  <!-- БЫЛО -->
    `
    # Даты сессий через запятую в обратном порядке в формате iso8601
    collect_stats_from_users(report, users_objects) do |user|
      { 'dates' => user.sessions.map{|s| s['date']}.map {|d| Date.parse(d)}.sort.reverse.map { |d| d.iso8601 } }
    end
    `
  <!-- СТАЛО -->
    `
    # Даты сессий через запятую в обратном порядке в формате iso8601
    collect_stats_from_users(report, users_objects) do |user|
      { 'dates' => user.sessions.map{|s| s['date']}.sort.reverse }
    end
    `
- как изменилась метрика
  К сожалению, существенного прироста показателей это не дало
  `
    время выполнения: 1.87 секунды
    ips: 0.414  (±19.2%)
  `
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  Теперь отчет callgrind.callgrind.out.29048 показал, что у нас на первом и втором месте IO read (476 ms) и IO write (396 ms), которые вызываются для чтения и записи файла. После них Array::each (254 ms, но инклудит в себе вызовов еще на 780 ms)  

### Ваша находка №2
- какой отчёт показал главную точку роста
  Отчет qcachegrind profilizers/ruby_prof_reports/callgrind.callgrind.out.3414
  сделал в профилайзерах вызов на парсинг фала в 1000 строк, теперь данные выглядят иначе. Теперь 83,56% времени занимает String::split


  Убрал тесты из task-1.rb в отдельную директорию, теперь оценка бенчмарка показыает более хорошие результаты
  `
    время выполнения: 1.14 секунды
    ips: 0.807  (±15.0%)
  `
  
- как вы решили её оптимизировать
  Попробуем изменить алгоритм, и просто обратить входящие данные в JSON, а затем распарсить на хэш, из которого сгенерим нужный нам result,
  думаю, можно сократить количество итераций и вызовов map и each таким образом.

  Для того, чтоб проверить, даст ли это прирост в быстродействии, я сравнил бенчмарк итераций each по массиву и по хэшу, потому что, по-видимому,
  избежать этой итерации не удастся в обоих вариантах. Но оценка бенчмарка показала, что массивы перебираются практически в два раза быстрей, чем хэши:

  Comparison:
  generate_array from 1000 rows:    30373.7 i/s
  generate hash from 1000 rows:    14795.4 i/s - /Users/ruslan/.rbenv/versions/2.6.5/lib/ruby/gems/2.6.0/gems/kalibera-0.1/lib/kalibera/data.rb:92: warning: BigDecimal.new is deprecated; use BigDecimal() method instead.
  2.05x  (± 0.02) slower
                     with 99.0% confidence

  поэтому от идеи с хэшем пришлось отказаться

  Тем не менее, метод split вызывается 2001 раз, значит, попробуем оптимизировать его использование. в цикле с разбором file_lines

  `  
    file_lines.each do |line|
      cols = line.split(',')
      users = users + [parse_user(line)] if cols[0] == 'user'
      sessions = sessions + [parse_session(line)] if cols[0] == 'session'
    end
  `
  только лишь для того, чтоб определить первый элемент. А потом повторно вызывается уже в методах parse_user и parse_session, попробуем избежать лишнего вызова.

- как изменилась метрика
  Оценка бенчмаркинга показала, что ips даже немного сократился
  `
    время выполнения: 1.17 секунды
    ips: 0.749  (±13.1%)
  `
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  Отчет callgrind.callgrind.out.16010
  При этом количество вызовов метода `split` сократилось вдвое, как и ожидалось - до 1001 раза на 1000 строк. Но время выполнения практически не изменилось и осталось на уровне 1 секунды (1,045 сек, а было 1,023 сек (отчет callgrind.callgrind.out.3414))
  <!-- единицы измерения в программе callgrind будем считать за микросекунды - 1_000_000 ед = 1 сек -->

  Для 1000 строк в файле 1001 вызов метода split выглядит минимально возможным значением, при этом на втором месте по времени выполнения стоит IO::read, который также оптимизировать не представляется возможным, на третьем месте - метод Array::select, который вызывается 154 раза, но занимает всего 28_082 единицы (0,028 сек), то есть более, чем в 37 раз меньше, чем метод `split`

  Таким образом, попробуем просто провести общий рефакторинг метода work (и смежных методов) и измерить performance

### Ваша находка №3
- какой отчёт показал главную точку роста

- как вы решили её оптимизировать
  в ходе оптимизации метода work и программы в целом, я упразднил использование класса User, а также сущности sessions, собирая ее информацию под соответствующим ключом в хэше `@users`. Там же под ключом `:statistics` стал собирать статистику юзера уже при парсинге строк из файла, что позволило отказаться от использования метода `collect_stats_from_users`, и многократного его вызова во второй половине метода work. Кроме того, все хэши в коде используют строки в виде ключей, а это, как известно, дополнительная нагрузка на память, поэтому я заменил их на символы. Также в ходе рефакторинга удалось отказаться от разного рода повторяемых методов.

  
- как изменилась метрика
  `
    время выполнения: 1.18 секунды
    ips: 0.820  (±13.9%)
  `
  Профилайзер показал в отчете callgrind.callgrind.out.40533, что самый долго выполняемый метод по-прежнему `split`, но теперь он занимает более 93% выполнения программы. На втором месте `IO::read`, а на третьем `parse_session`, который занимает лишь 0,16% общего времени выполнения, 1_880 единиц, что почти в 590 раз меньше, чем `split`.

### Ваша находка №3
- какой отчёт показал главную точку роста
  внимательный пересмотр кода
- как вы решили её оптимизировать
  я обнаружил, что совершенно напрасно занимаюсь парсингом строки, сохраняя и обрабатывая все ее элементы. Они в вычислении нужного нам результата у меня не используются. В эту обработку входило присвоение нескольких переменных, а также создание хэша и сохранение его в массив к существующему хэшу. А также вообще отказался от использования хэшей в пользу массивов, за исключением одного лишь раза, когда требуется выводить итоговый отчет.

  
- как изменилась метрика
  Убрав эти лишние строки, получил такую метрику
  `
    время выполнения: 1.19 секунды
    ips: 0.815  (± 7.8%)
  `
  Но что важнее, с файлом data_large метод стал выполняться около 21 секунды, тогда как прежде выполнялся за 37 в лучшем случае, а иногда и за 40+

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 2.09 секунды c ips: 0.474 до 1.18 секунды и ips 0.820. Кроме того, изначальный тест на performance с проверкой на линейную прогрессию перестал проходить, и прогрессия стала лоагрифмической. Однако, видимо, этому параметры доверять особо нельзя, потому что и проверка на логарифмическую прогрессию частенько падает, а взамен выдает то линейную, то экспоненциальную, то ту же самую логарифмическую, но как ошибку. `expected block to perform logarithmic, but performed logarithmic`

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы я написал тесты на время выполнения, на ips, а также на прогрессию, но, думаю, ему нельзя доверять, если честно. 

