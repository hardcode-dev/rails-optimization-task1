# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: Я оценивал скорость выполнения отдельных методов программы, чтобы находить места, где можно ускорить. Когда я понимал, что данное место ускорить уже нельзя, я смотрел следующее узкое место.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: Я смотрел процент времени выполнения методов программы, далее правил их и сравнивал новый способ работы замедляет или нет.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался Я воспользовался rubocop-perfomance, ruby-prof.

Вот какие проблемы удалось найти и решить

### Ваша находка №1
1. Субъективно показалось, что очень сложно разобраться в коде. Также не хватало инструментов для локализации проблемы.
2. Я решил, что нужно разнести программу по отдельным файлам. А также ввести структуру проекта.
   Изменил алгоритм, чтобы он принимал путь до файла.
   Написал тест, чтобы понять укладывается текущая реазицаия в необходимую скорость выполнения.
   Добавил rubocop и rubocop performs, чтобы сделать первый шаг оптимизации на основе статического анализа.
   Создал наборы данных в 128, 16, 8, 4, 2 раза меньше исходных.
   Провел тесты может ли программа на входных данных в 128 раз меньше отработать за целевое время.
3. Добавление rubocop performs не дало никаких бенефитов.
4. Тест оценки времени на данных в 128 раз меньше укладывается в необходимое время.
   Но на данных в 16 раз меньше от исходных не укладывается в необходимое время.

### Ваша находка №2
1. RubyProf::FlatPrinter показал, что 52% времени программа выполняет Array#select,
   а 31% времени работы происходит Hash#[]. Общее время работы программы на данных в 128 раз меньше исходных было 41.915181.
   Это значит что основная проблема сейчас в поиске сессий для пользователя.
2. Сессии решено было хранить в структуре данных Hash. Где в качестве ключа использовался user_id,
   а в качесте значения массив из сессий для этого пользователя. Также пришлось изменить подсчет unique_browsers.
   Так как заниматься деструктуразицией сессий было иррационально, было принято решение хранить их в структуре данных Set,
   которая обеспечивает уникальность данных. И записывать браузеры во время билдинга данных.
   Также по причине смены структуры данных для хранения сессий, было принято решение считать количество сессий во билдинга данных.
3. Время выполнения программы стало 0.366013
4. В итоге Array#select перестала быть главной точкой роста. А Hash#[] со второй позиции и 31% времени выполнения программых
   переместилось на 3 место. И стало занимать 10.58% времени программы.

### Ваша находка №3
1. RubyProf::FlatPrinter показал, что 20.93% времени программа выполняет Array#each,
   а 10.78% времени работы происходит String#split.
2. Array#each вызывался 9 раз. 1 раз - при парсинге данных, 1 раз для билдинга объектов пользователя и 7 раз для подсчета статистики.
   Таким образом было решено не вызывать отдельно подсчет статистики для каждого из пользователей, а считать статистику вместе.
3. Время выполнения программы стало 0.312654.
4. Количество вызовов Array#each = 3 она все еще осталось главной точкой роста, но % времени изменился до 15.53%

### Ваша находка №4
1. RubyProf::FlatPrinter показал, что 15.53% времени программа выполняет Array#each,
   а 10.32% времени работы происходит String#split.
2. Было решено не создавать объекты пользователей, а работать с исходной структурой данных.
3. Время выполнения программы стало 0.286526.
4. Количество вызовов Array#each = 2 она все еще осталось главной точкой роста, а % времени изменился до 15.69%

### Ваша находка №5
1. RubyProf::FlatPrinter показал, что 15.59% времени программа выполняет Array#each,
   а 12.11% времени работы происходит String#split.
   Основное время выполнения Array#each на данном этапе показалось обоснованным,
   так как это был парсинг данных и подсчет статистики. Было решено сосредоточится на второй точке роста,
   а именно на String#split.
2. При парсинге данных, одна и та же строка сплитилась дважды.
   В результате оптимизации она сплитилась один раз для каждой строки.
3. Время выполнения программы стало 0.280968.
4. Количество вызовов String#split = количеству строк, а % времени изменился до 8.50%. Это перестало быть клавной точкой роста.


### Ваша находка №6
1. Далее было принято решение использовать объем данных в 16 раз меньше исходных.
   RubyProf::FlatPrinter показал, что 30.14% времени программа выполняет Array#+,
   а 12.31% времени работы происходит Array#each. Время выполнения на новых данных стало 2.959081
2. При парсинге данных, происходило сложение массивов данных, для добавления данных users.
   Вместо это было принято решение аппендить данные в сущестующий массив.
3. Время выполнения программы стало 2.215102.
4. В итоге Array#+ перестала быть главной точкой роста.


### Ваша находка №7
1. Было принято решение тестировать алгоритм на данных в 4 раза меньше исходных.
   RubyProf::GraphPrinter показал, что 59.34% времени программа выполняет StatisticsService#collect_stats_from_users.
   Там выполняется основной подсчет статистики, где происходит 6 отдельный проходов по сессиям пользователя.
   Также было обноружено, что вызов upcase для браузера происходит несколько раз.
2. Подсчет начал проходить однажды по хэшу их сессий. Пользователи храняться в структуре данных Хэш, чтобы upcase для браузера происходит однажды при парсинге данных.
3. Время выполнения до 14.24009203800233. Время выполнения программы стало 9.740926656995725.
4. В результате изменений кода подсчет статистики в целом занимает значительную часть работы, но перестало быть главной точкой роста.

### Ваша находка №8
1. RubyProf::FlatPrinter показал, что 20.31% времени программа выполняет String#split.
   Данный метод разбивает исходный файл на массив строк. А оставшееся время разбивает строки на колонки.
2. Использование csv замедлило программу. Поэтому было решено продолжить работать с файлом. Удалось заменить на readlines.
3. Время выполнения до 9.571552. Время выполнения программы стало 9.293455.
4. Все также является точкой роста выполнения программы.
   Но занимает значительно меньшее время в выполнении программы - 17.84%

### Ваша находка №9
1. RubyProf::GraphPrinter показал, что подсчеты map занимают основное время в калькуляции статистики, а именно 11.08%.
2. Было принято решение не делать цикла, а подсчитывать отдельно каждый элемент статистики.
3. Время выполнения до 8.646485162003955. Время выполнения программы стало 7.422079.
4. Это перестало быть точкой роста.

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с того, что данные в 128 раз меньше исходных обрабатывались 41.915181 сек, а в результате они обрабатываются 0.150007 сек. А обработка всех данных выполняется и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы для защиты от регрессии я написал тесты с ожидаемой скоростью выполнения для меньших наборов данных. Чтобы не тестировать на больших данных и не грузить CI.

