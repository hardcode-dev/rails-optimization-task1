# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: время выполнения метода work

ноут на питании, включен режим perfomance

результаты первоначальных замеров:
строк  |    время       | время с откл GC |  доля от полного объема 
8125   -  0.859123413   -   0.883684986   - 1 / 400
16250  -  3.276928355   -   4.276658595   - 1 / 200
32500  - 18.127671497   -  24.047814292   - 1 / 100
65000  - 82.723400021   - 112.887070381   - 1 / 50

амсиптота близка к O(N^2), то есть на полном объеме понадобится около 180000 - 210000 c

Почему-то результаты пока не стабильны.
Не понятна история с GC. Почему-то при отключении время выполнения растет.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 5 с

Вот как я построил `feedback_loop`: для измерения изменений метрики выбрал данные объемом 16250 строк (1/200 от полного объема) - этот объем изначальная версия метода work обрабатывает около 3,3 с. На мой взгляд это оптимально, потому что позволяет не тратить слишком много времени на проверку гипотез, но при этом покажет заметную разницу в результатах. Для удобства добавил аргумент file_name методу work, в котором передается имя файла с данными, чтобы за один запуск работал метод с контрольным файлом 'data_16250.txt' и проходил тест, использующий 'data.txt'.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался RubyProf(FlatPrinter)

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- RubyProf(FlatPrinter) показал, что  91 % времени в работе Array#select

 %self      total      self      wait     child     calls  name
 91.35      7.716     7.716     0.000     0.000     2468   Array#select                   
  3.47      8.424     0.293     0.000     8.132       10   Array#each      

- Оптимизация: сгруппировать сессии по user_id при помощи метода Enumerable#group_by, что позволит отказаться от многократного прохода select по всей коллекции сессий. Получение сессий пользователя по id из полученного Хэша.
- Текущий показатель метрики - 0.466655555.  Ускорение в 7 раз. Возможно надо было взять тестовый объем побольше. 
-  RubyProf(FlatPrinter) - новый отчет - новая точка роста

 %self      total      self      wait     child     calls  name
 42.81      0.195     0.195     0.000     0.000    13782   Array#all?                     
 35.66      0.433     0.162     0.000     0.271        4   Array#each                     
 13.85      0.063     0.063     0.000     0.000    32501   String#split        

### Ваша находка №2
- RubyProf(GraphHtmlPrinter) 
96.13%	33.00%	0.60	0.21	0.00	0.39	11	Array#each
вызывался 11 раз (1/11	Enumerable#group_by,	7/11	Object#collect_stats_from_users, 3/11	Object#work)
- Оптимизация: в парсинге строк файла заменить Array# + (Concatenation) на << (apend)
- Текущий показатель метрики - 0.268053728. снижение на 42 % от предыдущего показателя. 
- новый отчет 94.53%	17.93%	0.58	0.11	0.00	0.47	11	Array#each - не главная текущая проблема

### Ваша находка №3
- RubyProf(CallStackPrinter) - честно говоря хоть и нашлась точка роста, но как-то пока не очевидно.
38.24% (73.04%) Array#all? [13782 calls, 16250 total]
Поэтому решил воспользоваться еще один профайлером  RubyProf(CallTreePrinter) - вот здесь оказалось очень удобно искать (Call Graph просто супер)

- есть два места где вызывается all? 
 1. при проверке, что пользователь всегда использовал только браузер CHROME - в данном случае решил произвести замену на обратную проверку - не  использовался ли хоть раз другой браузер через Array#any?. Но в данном случае хоть и произошло снижение количества вызовов, на метрике стабильного снижения не было заметно.  Принял решение правку оставить
 2. при подсчёте количества уникальных браузеров. 
 Решил использовать класс Set для сбора коллекции браузеров, так как проверка на наличие элемента в коллекции для Сетов работает быстрее.
- Текущий показатель метрики - 0.167523401. Снижение на 37 % от предыдущего результата, или в 20 раз от начального.
- так как от метода я избавился, то точка роста изменилась ))

### Ваша находка №4
- Перешел к использованию stackprof
==================================
  Mode: wall(1000)
  Samples: 165 (4.07% miss rate)
  GC: 0 (0.00%)
==================================
     TOTAL    (pct)     SAMPLES    (pct)     FRAME
       165 (100.0%)         119  (72.1%)     Object#work
       110  (66.7%)          23  (13.9%)     Object#collect_stats_from_users
        15   (9.1%)          15   (9.1%)     Object#parse_session

                                  |    39  | def collect_stats_from_users(report, users_objects, &block)
  110   (66.7%)                   |    40  |   users_objects.each do |user|
    9    (5.5%) /     9   (5.5%)  |    41  |     user_key = "#{user.attributes['first_name']}" + ' ' + "#{user.attributes['last_name']}"
    8    (4.8%) /     8   (4.8%)  |    42  |     report['usersStats'][user_key] ||= {}
   91   (55.2%) /     4   (2.4%)  |    43  |     report['usersStats'][user_key] = report['usersStats'][user_key].merge(block.call(user))
    2    (1.2%) /     2   (1.2%)  |    44  |   end
                                  |    45  | end
                                  
точка роста в строке 43. 

- как подсказывает fasterer  - Calling blocks with call is slower than yielding. Заменю вызов block.call -> yield

- c метрикой возник вопрос, она не изменилась, снова сделал замер без правки и получил 0.19115485 возможно прошлый замер был неточным
Текущий показатель метрики - 0.164584641
- отчет лучше не стал 
==================================
  Mode: wall(1000)
  Samples: 144 (4.00% miss rate)
  GC: 0 (0.00%)
==================================
     TOTAL    (pct)     SAMPLES    (pct)     FRAME
       144 (100.0%)         110  (76.4%)     Object#work
        97  (67.4%)          15  (10.4%)     Object#collect_stats_from_users
        13   (9.0%)          13   (9.0%)     Object#parse_session

и в самом методе
85   (59.0%) /     3   (2.1%)  |    43  |     report['usersStats'][user_key] = report['usersStats'][user_key].merge(yield user)

Но само улучшение решил оставить, так как метрика стабильно меньше. Да и fasterer обманывать не станет. 

### Ваша находка №5
- пользовался прошлым отчетом
- есть рекомендация использовать методы с ! когда объект должен изменится. Решил воспользоваться в данном случае merge!
- Текущий показатель метрики - 0.161505734
- В отчете есть улучшение
==================================
  Mode: wall(1000)
  Samples: 147 (3.92% miss rate)
  GC: 0 (0.00%)
==================================
     TOTAL    (pct)     SAMPLES    (pct)     FRAME
       147 (100.0%)         110  (74.8%)     Object#work
        93  (63.3%)          17  (11.6%)     Object#collect_stats_from_users

   78   (53.1%) /     2   (1.4%)  |    43  |     report['usersStats'][user_key].merge!(yield user)

### Ваша находка №6
- попробовал stackprof с флэймграфом, красиво, но кроме того, что проблема все еще в collect_stats_from_users, ничего нового не узнал. Запустил rubyprof cо всеми отчетами. В GraphHtmlPrinter видно, что в стэке each много вызовов map 19.16%	0.14	0.05	0.00	0.08	27150	Array#map  и	11.36%	0.07	0.03	0.00	0.03	13782	<Class::Date>#parse. 
CallStack  показывает, что из точка роста 25.80% (57.72%) <Class::Date>#parse [13782 calls, 13782 total]

- Оптимизировал используя парсинг с методом strptime c указанием патерна.
- Текущий показатель метрики - 0.1198 с
- 5.77%	4.98%	0.01	0.01	0.00	0.00	13782	<Class::Date>#strptime

### Ваша находка №7
- запустил на полном объеме метод work, решил посмотреть с rbspy, что там происходит на ходу. Очень много времени работал  users.each в сборе статистики по юзерам.
- внутри each есть конкатенация массивов, как показала Оптимизация № 2, - это крайне медленный метод. Заменю на <<.
- метрика практически не изменилась, но видимо сказывается слишком маленький объем данных, потому что работа с полным объемом данных завершилась за 50 с, а до последней правки я останавливал процесс на 8 минуте, не дождавшись завершения.
- данная оптимизация обнаружена не по отчету.

### Ваша находка №8
- stackprof
==================================
  Mode: wall(1000)
  Samples: 117 (5.65% miss rate)
  GC: 0 (0.00%)
==================================
     TOTAL    (pct)     SAMPLES    (pct)     FRAME
       117 (100.0%)          73  (62.4%)     Object#work
        66  (56.4%)          21  (17.9%)     Object#collect_stats_from_users
        13  (11.1%)          13  (11.1%)     Object#parse_session
         4   (3.4%)           4   (3.4%)     Object#parse_user
         
                                  |    39  | def collect_stats_from_users(report, users_objects, &block)
   66   (56.4%)                   |    40  |   users_objects.each do |user|
   10    (8.5%) /    10   (8.5%)  |    41  |     user_key = "#{user.attributes['first_name']}" + ' ' + "#{user.attributes['last_name']}"
    7    (6.0%) /     7   (6.0%)  |    42  |     report['usersStats'][user_key] ||= {}
   49   (41.9%) /     4   (3.4%)  |    43  |     report['usersStats'][user_key].merge!(yield user)
                                  |    44  |   end
- для оптимизации вызовов collect_stats_from_users, объединю все вызовы в один
- так как метрика перестала адекватно реагировать на изменения, решил использовать больший пакет данных на измерениях
метрика до последнего изменения - 1.346 с, новый показатель - 1.110 с
- измение отчета
==================================
  Mode: wall(1000)
  Samples: 756 (10.95% miss rate)
  GC: 0 (0.00%)
==================================
     TOTAL    (pct)     SAMPLES    (pct)     FRAME
       756 (100.0%)         485  (64.2%)     Object#work
       153  (20.2%)         153  (20.2%)     Object#parse_session
       338  (44.7%)          58   (7.7%)     Object#collect_stats_from_users

### Ваша находка №9
- все профайлеры показывают, что самый медленный стэк - это парсинг дат
- если сравнить входные данные и выходные видно, что никаких особых преобразований не требуется. Преобразование строки в дату в текущей состоянии не требуется. Сортировка строки даст необходимый результат. Поэтому принял решение исключить из логики преобразование в Дату.
- Метрика 0.877 (предыдущйи показатель - 1.110 с)
- отчеты показывают, что Object#collect_stats_from_users - больше не точка роста

### Ваша находка №10
- rubyprof callstack -  самый медленный метод 14.37% (32.35%) Object#parse_session [54987 calls, 54987 total]
rubyprof flat - выделяет большое количество вызовов #split

 %self      total      self      wait     child     calls  name                           location
 25.87      0.524     0.162     0.000     0.363        6   Array#each                     
 19.50      0.122     0.122     0.000     0.000   130001   String#split         
- метод #work разделяет строки на слова, но в parse_session передает строку, где она снова разделяется на слова. Поэтому изменяю #parse_session на получение в аргументе массива слов, что позволит избавится от двойного вызова split на каждой строке.
- Метрика 0.762 (предыдущйи показатель - 0.877 с)
- 4.61% (13.97%) Object#parse_session [54987 calls, 54987 total] -  не самый медленный

 %self      total      self      wait     child     calls  name                           location
 28.42      0.444     0.153     0.000     0.290        6   Array#each                     
 15.90      0.118     0.086     0.000     0.032    30041   Array#map                      
 11.51      0.062     0.062     0.000     0.000    65001   String#split      

### Ваша находка №11
- скорее фикс, пропустил один вызов collect_stats_from_users при объединении
- добавить к объединенному вызову
- Метрика 0.678 (предыдущйи показатель - 0.762 с)

 
## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 327.1511 с до 0.678 с и уложиться в заданный бюджет (время выполнения на полном объеме 24-25с). К сожалению тест на линейную асимптотику метод не проходит, но так оптимизация позволила уложиться в бюджет, дальнейшая оптимизация будет излишней.
Для удобства контроля работы добавил два прогресс-бара на наиболее продолжительные операции: на парсинг файла и на сбор статистики по пользователям.


## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы добавлен тест на производительность.

