# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы, основной метрикой для понимания эффективности оптимизации программы является время выполнения.

Цель — уложиться в 30 секунд.

К важной метрике я бы добавил изменение асимптотики выполения программы со степенной до линейной.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений.
Вот как я построил `feedback_loop`: используем профайлер -> вносим изменения —> пишем тесты -> сравниваем результы

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я решил сделать следующие шаги:

1) для начала необходимо отерефакторить программу, чтобы было максимально удобно работать с кодом, для этого я вынес тесты. Учитывая, что сам по себе код не очень большой, сильное разбиение не имеет большого смысла.
Для запуска начального теста на логику необходимо выполнить команду `ruby ./test/initial_test.rb`

2) необходимо подобрать фрагмент данных, который будет отрабатывать за комфортное время, я выбрал 20_000 строк.
Чтобы удобно обрезать файл с данными используем `head -n 10000 data/data_large.txt > data/data_10_000.txt`
Для быстрой оценки времени использовал команду `time ruby task-1.rb`

3) оценить начальную асимптотику
1_000   | 0,119
---------------
10_000  | 0,984
---------------
20_000  |  3,361
---------------
40_000  | 14,254

Из таблицы видно, что асимптотика степенная, больше чем O(N^2)

3) Настроил тестовую (perfomance) среду
Подключил гем ruby-prof и stackprof

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- объем данных: 20_000 строк, начальное время 3,42 с
- основную точку роста показали все отчеты rubyprof, самый наглядный callstack.html, 92.15 % по времени занимает метод select.
- добавил rspec-benchmark, вынес запуск программы в отдельный файл. 
- исходя из кода программы решил отрефакторить код следующим образом: сгруппировать ссессии из массива в хеш, с ключами по user_id.
- Время уменишилось до 0,273 мс, удалось увеличить скорость выполнения почти в 10 раз.
- Базовый тест проходит. 
- Исправленная проблема исчезла

### Ваша находка №2
- объем данных: 60_000 строк, начальное время 4.22
- ruby_prof (callstack и graph) однозначно указывают, что надо обратить внимание на метод Array#+, который занимает 40% времени
- нужно переписать метод, чтобы не было сложения массивов, а нужный объект сразу добавлялся в конец массива (<<)
- скорость выполнения программы выросла до 517мс, и увеличилась почти в 10 раз
- Связанная с этим проблема исчезла

### Ваша находка №3
- объем данных: 200_000 строк, начальное время 5,753
- callstack показал основную точку роста в цепочке Each <- all? <- != <- String#==
- Это метод подсчета кол-ва уникальных браузеров, нужно отрефакторить его. Первое что приходит на ум, считать с помощью ключей хэша в месте первозначального парсинга браузеров.
- скорость выполнения программы стала 2,814 с, что в 2 раза меньше исходного значения
- отчет перестал показывать эту проблему как осноную точку роста

### Ваша находка №4
- объем данных: 200_000 строк, начальное время 2,814 с
- callstack показал основную точку роста в методе Date#parse 
- После детального разбора, становится ясно, что метод вроде и не особоо нужен. Даты и так приходят в нужном формате, нужно только отсортировать их.
- скорость выполнения программы стала 1,872 с, что в 1.5 раза быстрее исходного значения
- отчет перестал показывать эту проблему как осноную точку роста

### Ваша находка №5
- объем данных: 500_000 строк, начальное время 7,818 с
- сейчас немного сложнее, однозначно нелья сказать, что можно схватить жар-птицу, но определенные надежды вырисовываются в методе #collect_stats_from_user, хотя там все достаточно равномерно распределено, если смотреть отчет callstack и еще можно покопаться в #parse_session, но потом.
- После беглого просмотра видно что происходит 7-кратный вызов метода each для подсчета статистки по юзерам, первое что приходоит на ум, засунуть все эти методы сразу в блок.
- скорость выполнения программы стала 6,247 с, что немного быстрее, но не так как хотелось бы. Проверка block_given?, кстати, очень ухудшает производительность.
- Это победили, но по большому счету, надо оптимизировать каждый метод.

### Ваша находка №6
- объем данных: 500_000 строк, начальное время 6,247 с
- беру в работу #parse_session, по отчету callstack, он даст наибольший прирост, при меньшей работе на рефакторинг кода.
- Точки роста вижу в методе split, да он по сути дублируется в парсерах, убираю
- скорость выполнения программы стала 3,876 с, в два раза быстрее, неплохо за 30 секунд оптимизации.
- Это победили, но по большому счету, надо оптимизировать каждый метод.

### Ваша находка №7
Первый юбилей!!! 
- объем данных: 1_000_000 строк, начальное время 12,460 с
- по отчету callstack метод #collect_stats_from_users забирает больше половины времени, буду искать точки роста там.
- Точку роста наблюдаю в Hash#merge, на 150_000 тыс юзеров, больше 1 млн, вызовов, дальше только хуже. Пробую оптимизировать.
Сразу собираю в хэш, теперь 9,573, тесты прошли.
- Upcase браузера делаем при парсинге сессий, из статистики убираем, 8,324 с, неплохо.
- В парсинге сессий, обращает на себя внимание методы Array#[] и String#== , в процентах немного, но кол-во вызовов на двоих почти 5 млн, больше чем кол-во строк в 5 раз. Убираю лишнюю переменную - 8,002.
- Убрал сложение строк в имени, заменил на << - 7,726 с.
- Total_time и Longest_time, по сути работают с одним массивом, можно вынести его получение отдельно, и приведение к числу, делать при парсинге.
- Приведение к числу, немного помогло, а вот убрать функцию в отдельную переменную, а не вызывать ее два раза, сделало ситуацию хуже, немного странно, видимо руби внутри кеширует результат метода для повтороного использования. Идея с выделением бразуеров юзера в отдельную переменную, а не дергать map 3 раза, тоже не дало ощутимого эффекта.
- Заменил count на size - 7,277 с
- << вместо + 'min' - 7,061 c
- отчет показывает улучшение в методе #collect_stats_from_users, но по мелочи еще можно что-нибудь там придумать.

### Ваша находка №8
- объем данных: 1_000_000 строк, начальное время 7,061 с
- Возьмусь за метод each, который вызывается при парсинге файла, там есть куда расти. Много времени занимает split, но без него ничего не придумал. Много времени занимает парсинг сессий, но тут тоже пока ничего не придумал.
- Объединил условие для разбивки строк юзера и сессии, вместо двух if сделал блок if-else - 6,420 c

## Результаты
Убираю выводы в консоль, GC, запускаю с таймингом.
Итог `ruby main.rb  15,45s user 11,43s system 99% cpu 27,116 total`
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с очень большого времени, которое не удалось измерить до 27 секунд и уложиться в заданный бюджет.

Возможно не все утверждения верны, но выводы такие:
1) Если метод принимает блок, то он выполняется дольше, чем аналогичный метод без блока
2) Если упираешься в очень знакомый метод и кажется что все про него знаешь, то все равно не будет лишним посмотреть в документацию
3) При более менее равнозначных точка роста, выбирать надо ту, на исправление которой уйдет меньше времени. Может этого будет и достаточно.
4) Массивы имеют кучу супер-методов из коробки, но очень медленные
5) Лишняя запись в промежуточную переменную, часто ухудшает скорость.
6) Rubyway и красивость кода уходит на второй план в угоду оптимизации
7) Вывод в консоль тоже занимает много времени
8) Надо смотреть не только на время, но и количество вызовов метода, в идеале оно должно быть пропорционально кол-ву данных. Если 100 тыс строк, то и метода, сплит (например) должно быть 100 тыс.
9) Затраты на начальную настройку среды потом окупятся.
10) Автоматический запуск, теста нужен. В какой-то момент забываешь запускать и может просочиться ошибка.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы я использовал библиотеку rspec-benchmark, но в моём случае она оказалась достаточно глючной (использую Mac M1). Например тест на асмптотитку при каждом запуске с одним и тем же кодом, показывал все возможные варианты, но только не тот, на который ставил тест. Тест на скорость работы начал падать, когда в ход пошел метод << для строки. Видимо это связано с тем что идет сэмплирование, а объект уже поменялся.

