# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:
- 1к строк - это примерно ~40 ms
- 10к строк - это примерно ~1.8 sec
- 20к строк - это примерно ~10 sec

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.
- написал регрессионные тесты, для наблюдения изменениями после оптимизаций

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: 
- использование профилировщика для построения отчета
- анализ результата профилировщика для определение главной точки роста
- постараться исправить только главную точку роста
- запуск unit теста на проверку, то что скрипт не сломан и работает также
- запуск benchmarks для определения новых значений
- запуск регрессионных тестов чтобы проверить что не стало хуже
  - если все хорошо:
    - обновляем регрессионные тесты фиксируя новые значения
    - проверяем, если не укладываемся в бюджет, идем на следующий круг
  - если все плохо, откатываем изменения и идем круг сначала
 

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался *инструментами, которыми вы воспользовались*

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- для поиска главной точки роста был выбрал `stackprof-CLI`, с помощью профалера была найдена главная точка роста:
  - `user_sessions = sessions.select { |session| session['user_id'] == user['id'] }`
- изменить структуру `sessions`, `Array` to `Hash`, для того чтобы не итерироваться а получить доступ за константное время
- метрика изменилась:
  - 1к строк:
    - ~40 ms до
    - ~13 ms после 
  - 10к строк:
    - ~1.800 ms до
    - ~140 ms после
  - 20к строк:
    - ~10.000 ms - до
    - ~310 ms - после
  - были добавлены 2 новые метрики для более подробного исследования:
    - 100k строк - 1.9 sec
    - 300k строк(~10% of data_large.txt) - 6 sec
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  - в методе `work`:
    - pct - 98% было
    - pct - 78% стало
  - в методе `select`:
    - pct - 75% было
    - проблема перестала быть главной точкой роста

### Ваша находка №2
- для поиска главной точки роста был выбрал `callstack`:
  - `callstack` показал что главное точкой ростой являеться `each` метода `collect_stats_from_users`, но 70% времени уходит на методы вызываемые на блоке готорый передаётся в `collect_stats_from_users`, нужно посмотреть как используется этот метод
  - метод используется 7 раз для составление отчета
  - + 70% времени уходит на `map` и 60% от работы в `map` занимает парсинг даты
- решил вызывать метод `collect_stats_from_users` один раз, тем самым формируя  весь `report` одним вызовом этого метода
  - убрал парсинг даты и приведение к `iso8601`, т.к. это не нужно, тесты проходят
  - использовав `fasterer`, заменил `block.call -> yield`
  - т.к. названия всех браузеров начинается с имени браузера, использую `start_with?` вместо `~=`
  - убрал лишнии итерации с `map`
- как изменилась метрика:
  - 20к строк:
    - 20k 3.520 (± 0.0%) i/s - 18.000 in 5.122086s
    - 20k 7.699 (±13.0%) i/s - 39.000 in 5.103321s
  - 100к строк:
    - 100k 0.608 (± 0.0%) i/s - 4.000 in 6.616743s
    - 100k 1.209 (± 0.0%) i/s - 7.000 in 5.811072s
  - 300к строк:
    - 300k 0.181 (± 0.0%) i/s - 1.000 in 5.519391s
    - 300k 0.396 (± 0.0%) i/s - 3.000 in 7.593606s
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  - главной проблемой стала лишние `split` 

### Ваша находка №3
- для поиска главной точки роста был выбрал `callstack`:
  - главной проблемой стала лишние `split`
  - тут же было замечено что долгий парсинг `Hash` to `Json`
- как вы решили её оптимизировать
  - убрал сплит из парсинга сессии и юзера
  - добавил гем `oj`
  - для сравнения добавил новую метрику в 1м строк и убрал 20к
- как изменилась метрика:
  - 100к строк:
    - 100k      1.293  (± 0.0%) i/s -      7.000  in   5.481550s
    - 100k      1.443  (± 0.0%) i/s -      8.000  in   5.558614s
  - 300к строк:
    - 300k      0.393  (± 0.0%) i/s -      2.000  in   5.094596s
    - 300k      0.410  (± 0.0%) i/s -      3.000  in   7.393692s
  - 1м строк:
    - 1m      0.096  (± 0.0%) i/s -      1.000  in  10.421747s
    - 1m      0.130  (± 0.0%) i/s -      1.000  in   7.705423s
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  - главной проблемой не является `split`
  - зафиксирую результать и проверю на попадание в бюджет
  - метрика для `data_large`:
    - data_large      0.027  (± 0.0%) i/s -      1.000  in  36.907724s
    - в бюджет не укладываюсь, буду смотреть что можно еще сделать

### Ваша находка №4
- для поиска главной точки роста был выбрал `callstack`:
  - главной проблемой стала лишние `upcase`
  - заменить доступ к `Hash` со строк на символы
  - небольшая доработка в инициализации `User`
- как вы решили её оптимизировать
  - `upcase` вызываю один раз при парсинге основного файла
  - доступ к `Hash` за менил на символы
  - убрал лишние манипуляции при сохранении `User`
- как изменилась метрика:
  - 100к строк:
    - 100k      1.160  (± 4.1%) i/s -      6.000  in   5.178507s
    - 100k      1.223  (± 5.8%) i/s -      7.000  in   5.763894s
  - 300к строк:
    - 300k      0.454  (±16.0%) i/s -      3.000  in   6.729087s
    - 300k      0.453  (±14.3%) i/s -      3.000  in   6.759633s
  - 1м строк:
    - 1m      0.150  (± 0.0%) i/s -      1.000  in   6.652744s
    - 1m      0.139  (± 0.0%) i/s -      1.000  in   7.181373s
  - data_large | ~3м строк:
    - data_large      0.030  (± 0.0%) i/s -      1.000  in  33.391210s
    - data_large      0.033  (± 0.0%) i/s -      1.000  in  30.308000s
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  - пофиксил мелкие недочеты, получил бюджетное значение

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 10 секунд на 20к строк и уложиться в заданный бюджет.

Удалось достичь результата без переписывания "всего", а именно следуя feedback loop и исправляя главные точки роста.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы были написаны тесты.
