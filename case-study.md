# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:

Бюджет у нас в секундах, поэтому будем измерять время выполнения программы в секундах, с помощью `benchmark`. Так как программа с полным файлом слишком долго выполняется, я решил взять первую тысячу строк, потом х2, х4, х8, x16, чтобы посчитать время выполнения и ассимптотику.

Результаты измерений с исходным кодом программы:

| Количество строк | Среднее время выполнения |
|:----------------:|:------------------------:|
| 1 000            | 0.041403                 |
| 2 000            | 0.123288                 |
| 4 000            | 0.402989                 |
| 8 000            | 1.773411                 |
| 16 000           | 7.679319                 |

На основании этих данных можно понять, что ассимптотика квадратичная или даже кубическая (коэффициент корреляции кубической регрессии чуть выше квадратичной), что не совсем укладывается в наш бюджет при выполнении программы с полным файлом на 3 млн строк :).

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 1-2 минуты.

Вот как я построил `feedback_loop`:

Я решил использовать предложенный в `readme` фидбек-луп, пробуя в каждой итерации новый способ профилирование, в итоге я работаю по следующей схеме:



## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался профилировщиками `ruby-prof` в режимах `Flat`,

Вот какие проблемы удалось найти и решить

### Находка №1 - `Array#select`
- `ruby-prof` в режиме `Flat`
- Честно говоря, первыми в голову пришли более глобальные идеи, но так как мы хотим двигаться постепенно, то решил начать с малого и сделать что-то с этим селектом. Появилась идея о том, что одна сессия может принадлежать только одному юзеру, поэтому, когда мы её привязываем к юзеру, её можно убрать из общего массива sessions. Погуглил метод, который работает как селект, но при этом удаляет выбранные элементы из старого массива, самым подходящим показался `#partition`.
- Как изменилась метрика:

|   Количество строк  |   Предыдущий результат  |   Новый результат  |   Разница  |   Разница (%)  |
|---------------------|-------------------------|--------------------|------------|----------------|
|   1 000             |   0,0414                |   0,0312           |   -0,0102  |   24,5         |
|   2 000             |   0,1233                |   0,0916           |   -0,0317  |   25,7         |
|   4 000             |   0,4030                |   0,2781           |   -0,1249  |   31,0         |
|   8 000             |   1,7734                |   0,9359           |   -0,8375  |   47,2         |
|   16 000            |   7,6793                |   3,7027           |   -3,9766  |   51,8         |

На первый взгляд это казалось хорошим результатом, но ассимптотика была не совсем понятна, поэтому я добавил файл на 32 000 строк и по результатам решил, что ассимптотика ухудшилась.

| Количество строк | Предыдущий результат | Новый результат | Разница | Разница (%) |
|:----------------:|:--------------------:|:---------------:|:-------:|:-----------:|
| 32 000           | 23,426666            | 14,165618       | -9,2610 | 39,5        |

- Отчёт профилировщика показывал, что по сути точка роста сохранилась, поменялось только её название :) Откатываем изменения.

### Находка №2 - тот же `Array#select`
- `ruby-prof` в режиме `Graph`
- Вернёмся к более глобальным идеям и одна из них состоит в том, чтобы ещё в первом цикле, который идёт по строкам файла, сразу же привязывать сессию к юзеру. Таким образом, если строка в файле является юзером - мы сразу инициируем объект `User` с пустым массивом сессий, а если это сессия, то ищем юзера в массиве с помощью `#find` по `id` и добавляем сессию к нему.
- Как изменилась метрика:

|   Количество строк  |   Предыдущий результат  |   Новый результат  |   Разница   |   Разница (%)  |
|---------------------|-------------------------|--------------------|-------------|----------------|
|   1 000             |   0,0414                |   0,02801          |   -0,0134   |   32,4         |
|   2 000             |   0,1233                |   0,07961          |   -0,0437   |   35,4         |
|   4 000             |   0,4030                |   0,21860          |   -0,1844   |   45,8         |
|   8 000             |   1,7734                |   0,70163          |   -1,0718   |   60,4         |
|   16 000            |   7,6793                |   2,64729          |   -5,0320   |   65,5         |
|   32 000            |   23,426666             |   9,94190          |   -13,4848  |   57,6         |
Результат лучше, но всё ещё непонятна ассимптотика, судя по последней строке, вероятно ухудшение производительности с ростом объема файла, возможно результат будет даже хуже, но теперь хотя бы есть идея на следующую итерацию!

- Основная точка роста теперь `Enumerable#find`

### Находка №3 - `Enumerable#find`
- `ruby-prof` в режиме `Callstack`
- Следующая идея состоит в том, чтобы использовать вместо `#find` индекс массива, каждый юзер будет теперь лежать в массиве на своём месте (индекс будет равен его id).
- Как изменилась метрика:

|   Количество строк  |   Предыдущий результат  |   Новый результат  |   Разница  |   Разница (%)  |
|---------------------|-------------------------|--------------------|------------|----------------|
|   1 000             |   0,02801               |   0,02093          |   -0,0071  |   25,3         |
|   2 000             |   0,07961               |   0,04759          |   -0,0320  |   40,2         |
|   4 000             |   0,21860               |   0,08643          |   -0,1322  |   60,5         |
|   8 000             |   0,70163               |   0,17006          |   -0,5316  |   75,8         |
|   16 000            |   2,64729               |   0,33588          |   -2,3114  |   87,3         |
|   32 000            |   9,94190               |   0,68953          |   -9,2524  |   93,1         |
Вот теперь положительный результат намного больше впечатляет! Ассимптотика близка к линейной.

- Основная точка роста теперь `Array#all?`

### Находка №4 - `Array#all?`
- Повторим наш профайлинг в конце предыдущей итерации, но теперь с помошью `stackprof` через `CLI`
- Основная точка роста в подсчёте уникальных браузеров, пробуем применить `#uniq` по браузеру на `sessions`.
- Как изменилась метрика:

|   Количество строк  |   Предыдущий результат  |   Новый результат  |   Разница  |   Разница (%)  |
|---------------------|-------------------------|--------------------|------------|----------------|
|   1 000             |   0,02093               |   0,01661          |   -0,0043  |   20,6         |
|   2 000             |   0,04759               |   0,03479          |   -0,0128  |   26,9         |
|   4 000             |   0,08643               |   0,06545          |   -0,0210  |   24,3         |
|   8 000             |   0,17006               |   0,13036          |   -0,0397  |   23,3         |
|   16 000            |   0,33588               |   0,28100          |   -0,0549  |   16,3         |
|   32 000            |   0,68953               |   0,50647          |   -0,1831  |   26,5         |
Результат на маленьких файлах улучшился, но ассимптотика как будто бы стала хуже, поэтому попробуем теперь взять файлы побольше.

|   Количество строк  |   Предыдущий результат  |   Новый результат  |   Разница  |   Разница (%)  |
|---------------------|-------------------------|--------------------|------------|----------------|
|   128 000           |   2,47679               |   2,14563          |   -0,3312  |   13,4         |
|   256 000           |   5,65019               |   4,54517          |   -1,1050  |   19,6         |
|   512 000           |   11,65178              |   9,16911          |   -2,4827  |   21,3         |
|   1 024 000         |   24,08076              |   21,97913         |   -2,1016  |   8,7          |

Результат на 1 млн строк всё ещё положительный.

- Основная точка роста теперь `<Class::Date>#parse`

### Находка №5 - `<Class::Date>#parse`
- `qcachegrind` скачался, поэтому сейчас профилируем с помощью `ruby-prof` в режиме `callgrind` и на этот раз 256 000 строк.
- Смотря на парсинг даты становится понятно, что есть лишние вызовы `#map`, а исходная дата и так в нужном формате, поэтому можем убрать парсинг и лишние вызовы цикла.
- Как изменилась метрика:

|   Количество строк  |   Предыдущий результат  |   Новый результат  |   Разница  |   Разница (%)  |
|---------------------|-------------------------|--------------------|------------|----------------|
|   128 000           |   2,14563               |   1,52997          |   -0,6157  |   -28,7        |
|   256 000           |   4,54517               |   3,74257          |   -0,8026  |   -17,7        |
|   512 000           |   9,16911               |   9,42722          |   0,2581   |   2,8          |
|   1 024 000         |   21,97913              |   16,74379         |   -5,2353  |   -23,8        |

- Следующая точка роста `Object#collect_stats_from_users`

### Находка №6 - `Object#collect_stats_from_users`
- `stackprof` и `speedscope.app`.
- Убираем много вызовов метода и собираем всю информацию за один вызов.
- Как изменилась метрика:

|   Количество строк  |   Предыдущий результат  |   Новый результат  |   Разница  |   Разница (%)  |
|---------------------|-------------------------|--------------------|------------|----------------|
|   128 000           |   1,52997               |   1,15728          |   -0,3727  |   -24,4        |
|   256 000           |   3,74257               |   2,57350          |   -1,1691  |   -31,2        |
|   512 000           |   9,42722               |   5,47149          |   -3,9557  |   -42,0        |
|   1 024 000         |   16,74379              |   11,28606         |   -5,4577  |   -32,6        |

- Следующая точка роста `Array#map`

### Находка №7 - `Array#map`
- `ruby-prof` и `qcachegrind`.
- Вижу в отчёте много вызовов `#map` и ищу в коде все вызовы. Вижу очень много повторных запусков `#map`, поэтому по максиму мержу все циклы в один и выполняю все расчёты внутри него.
- Как изменилась метрика:

|   Количество строк  |   Предыдущий результат  |   Новый результат  |   Разница  |   Разница (%)  |
|---------------------|-------------------------|--------------------|------------|----------------|
|   128 000           |   1,15728               |   1,13139          |   -0,0259  |   -2,2         |
|   256 000           |   2,57350               |   2,58305          |   0,0096   |   0,4          |
|   512 000           |   5,47149               |   5,35252          |   -0,1190  |   -2,2         |
|   1 024 000         |   11,28606              |   11,83044         |   0,5444   |   4,8          |
Результат примерно такой же.

- Следующая точка роста `Object#parse_session`

### Находка №8 - `Object#parse_session`
- `ruby-prof` и `qcachegrind`, `graph`.
- Вижу лишний `#split` в `parse_session` и `parse_user`, можно его не вызывать второй раз, а передать в метод.
- Как изменилась метрика:

|   Количество строк  |   Предыдущий результат  |   Новый результат  |   Разница  |   Разница (%)  |
|---------------------|-------------------------|--------------------|------------|----------------|
|   128 000           |   1,13139               |   0,90496          |   -0,2264  |   -20,0        |
|   256 000           |   2,58305               |   2,24072          |   -0,3423  |   -13,3        |
|   512 000           |   5,35252               |   4,22382          |   -1,1287  |   -21,1        |
|   1 024 000         |   11,83044              |   10,77716         |   -1,0533  |   -8,9         |
Есть улучшения.

- Дальше точки роста ещё более размыты, возможно вернулись к `Array#map`

### Находка №9 - `Array#map`
- `ruby-prof` и `qcachegrind`, `graph`.
- Вернулся к `Array#map` в блоке `#collect_stats_from_users`, убрал из `#map` свою реализацию нахождения максимальной сессии и суммирования, вернулся к методам `#max` и `#sum`, так как они должны работать быстрее. Убрал проверку на Internet Explorer, если уже понятно, что юзер всегда использовал хром. 
- Как изменилась метрика:

|   Количество строк  |   Предыдущий результат  |   Новый результат  |   Разница  |   Разница (%)  |
|---------------------|-------------------------|--------------------|------------|----------------|
|   128 000           |   0,90496               |   0,88443          |   -0,0205  |   -2,3         |
|   256 000           |   2,24072               |   2,07893          |   -0,1618  |   -7,2         |
|   512 000           |   4,22382               |   4,06883          |   -0,1550  |   -3,7         |
|   1 024 000         |   10,77716              |   9,55080          |   -1,2264  |   -11,4        |
Неплохое улучшение для 1млн строк.

- Дальше точки роста ещё более размыты, возможно вернулись к `Array#map`

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*

