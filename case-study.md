# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше 30 мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы 
я придумал использовать такую метрику:

Метрика:

    время полной обработки в секундах

Бюджет:

    30 секунд

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: 

1  Построить ассимптотику 1000/10_000-100_000 шаг 10000

2  Прикинуть зависимость времени работы програмы от размера обрабатываемого файла

3  Установить рубокоп_перфоманс. Сделать новую ассимптотику

3  Построить и проанализировать отчёт `ruby-prof` в режиме `Flat`;

4  Построить и проанализировать отчёт `ruby-prof` в режиме `Graph`;

5  Построить и проанализировать отчёт `ruby-prof` в режиме `CallStack`;

6  Построить и проанализировать отчёт `ruby-prof` в режиме `CallTree` c визуализацией в `QCachegrind`;

7  Построить дамп `stackprof` и проанализировать его с помощью `CLI`

8  Построить дамп `stackprof` в `json` и проанализировать его с помощью `speedscope.app`

9  Профилировать работающий процесс `rbspy`;

10 Добавить в программу `ProgressBar`;

11 Постараться довести асимптотику до линейной и проверить это тестом;

12 Написать простой тест на время работы: когда вы придёте к оптимизированному решению, замерьте, сколько оно будет работать на тестовом объёме данных; и напишите тест на то, что это время не превышается (чтобы не было ложных срабатываний, задайте время с небольшим запасом);

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался *инструментами, которыми вы воспользовались*

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- построил ассимптотику, код запуска:
  
      ruby assimptotics.rb
  
  Assimptotics results:
  
  1000: 0 sec;
  
  10000: 1 sec;
  
  20000: 6 sec;
  
  30000: 14 sec;
  
  40000: 30 sec;
  
  50000: 52 sec;
  
  60000: 75 sec;
  
  70000: 102 sec;
  
  80000: 133 sec;
  
  90000: 177 sec;
  
  100000: 225 sec;
  
  Зависимость нелинейная, похожа на квадратичную. Используя квадратичное уравнение по двум точкам 50000 и 100000
  получилось завершение программы на моем оборудовании за 371297 сек = 103 часа.

### Ваша находка №2
- обработал rubocop-performance, тест проходит:
  
      rubocop task-1.rb -A
  1 file inspected, 118 offenses detected, 82 offenses corrected

  изменения по большей части синткасические сахарные, ушли лишние сложения строк и переменных, поэтому время работы сократилось только на 10%.
  Оставил три точки измерения:

  30000: 12 sec;
  
  50000: 45 sec;

  100000: 197 sec;


### Ваша находка №3
- запустил rbspy  (скрипт запуска и результат в /1-rbspy/).
  В выходном файле (верхняя часть) получил 

      % self  % total  name
      83.30    83.30  block (2 levels) in work - /home/filonov/optim/rails-optimization-task1/task-1.rb:105
      14.06    97.27  select [c function] - (unknown):0
  
- 83% времени занимает работа блока (второго уровня) в 105 строке. 
  Т.к. на каждого пользователя каждый раз запускается фильтр по всем сессиям 
  решил подготовить сессии пользователей заранее, получив один проход по сессиям.
- значение метрики сократилась в ~20 раз. Добавил новое значение для метрики - 500_000

  30000: 0 sec;
  
  50000: 2 sec;
  
  100000: 5 sec;

  500000: 175 sec;


- Отчет профилировщика изменился:

      % self  % total  name
      92.47    93.43  block in work - /home/filonov/optim/rails-optimization-task1/task-1.rb:57
      2.52     2.54  block in work - /home/filonov/optim/rails-optimization-task1/task-1.rb:112

### Ваша находка №4
- запустил RubyProf  (скрипт запуска и результат в /2-ruby-prof-flat/).
  В выходном файле (верхняя часть) получил

      %self      total      self      wait     child     calls  name                           location
      92.81    216.061   201.285     0.000    14.777       11   Array#each                     
      2.70      5.884     5.859     0.000     0.024   500000   Array#all?                     
      1.05      2.281     2.281     0.000     0.000  1000001   String#split

- 92% времени занимает работа блока each, который встречается 5 раз. Rbspy лучше, т.к. указывает строку.
  С учетом данных rbspy оптимизирую первый each: 
    
  a) Массив пользователей и сессий создается через +, что заставляет память выделять место под новый массив.
  Метод << или push использует тот же массив. Главная причина.
  
  б) Split строки на массив происходит три раза. Убираю.
  
  в) if заменяю на case, чтобы в случае строки с пользователем, анализ на сессию уже не производился.
  
- значение метрики сократилась в ~10 раз. Добавил новое значение для метрики - 1000_000

  50000: 1 sec;
  
  100000: 1 sec;
  
  500000: 13 sec;

  1000000: 41 sec;

- Отчет профилировщика изменился:

      %self      total      self      wait     child     calls  name                           location
      37.03      0.000     0.000     0.000     0.000        1   <Class::IO>#read               
      30.11      0.000     0.000     0.000     0.000        1   [global]#                      ruby-prof-flat.rb:10

### Ваша находка №4
- запустил RubyProf в режиме graph (скрипт запуска и результат в /3-ruby-prof-graph/).
  В выходном файле получил

        100.00% 	0.28% 	21.19 	0.06 	0.00 	21.13 	1 	Object#work 	48
        13.18 	6.17 	0.00 	7.01 	4/11 	Array#each 	54
        7.07 	0.00 	0.00 	7.07 	7/7 	Object#collect_stats_from_users 	121

  ниже array.each раскладывался

        95.61% 	35.26% 	20.26 	7.47 	0.00 	12.79 	11 	Array#each 	
        5.62 	5.60 	0.00 	0.02 	500000/500000 	Array#all? 	87

  Выделил две основные проблемы в 87 строке all и 121 работа функции collect_stats_from_users

- В 87 строке работа уходит на работу блока each и в нем all:

  a) Заменяю all? на include?, формирование массива uniqueBrowsers изменяю с оператора + на <<
  
- Функция collect_stats_from_users вызывается 7 раз отдельно формируя каждый показатель по пользователям.
  
  а) Заменил на один вызов вместо 7.

  б) Убрал в функции map второго уровня  


- значение метрики сократилась на ~20%.

  100000: 1 sec;
  
  500000: 9 sec;
  
  1000000: 35 sec;

- Отчет профилировщика изменился соответствующим образом, снизились top показатели

### Ваша находка №5
- запустил RubyProf в режиме callstack (скрипт запуска и результат в /4-ruby-prof-callstack/).
  В выходном файле получил 57% Array.each, 36% collect_stats_from_users
  Array.each распадался на 5% string.split, который уже не поправить, array.include? и Object#parse_session.
  Решил обратить внимание на Object#parse_session, поменял формирование HASH ключи со string на символ, а 
  также parse_user. Все это дало прироста только 2%. Понял, что ошибочно обратил на это внимание, а 50%
  работы происходило внутри Array.each (4 места), который не раскрывался в html на вложенные функции. 
  Обнаружил в Array.each ранее не оптимизированное место в подсчете уникальных 
  браузеров: аналогично ранее исправленным примерам применялся оператор + вместо операторов << или push
  
  Добавил в ассимпотитку 3000_0000. Результаты после оптимизации, значение метрики сократилось в три раза:

  100000: 1 sec;
  
  500000: 6 sec;
  
  1000000: 11 sec;

  3000000: 44 sec;

  Финальный результат еще не достигнут.
       
- Новый отчет профилировщика кардинально изменился:

      58.30% (58.30%) Object#collect_stats_from_users [1 calls, 1 total]
    
      32.12% (32.12%) Array#each [4 calls, 5 total]

   В топ 2 уровня вышел Array#map 42%.

### Ваша находка №6
- запустил RubyProf в режиме callgrind (скрипт запуска и результат в /5-ruby-prof-callgrind/).
  В интерфейсе Kcachegring получил после object.work строку Array.each, который вызывался (callers) collect_stats_from_users
  Array.each раскладывался в интерфейсе на Array.map, который вызывался больше 1млн раз. Решил оптимизировать map.
  Т.к. collect_stats_from_users map по users.sessions вызывался несколько раз, сделал один обход массива 
  users.sessions методом each с формирование необходимых данных в подмассивах.
  
  Также оптимизировал один лишний вызов map при формировании report[:allBrowsers]

- снова запустил rubyProf в режиме callgrind. Интерфейс Kcachegring показывал в топ Array.each, но сейчас данный метод
  расскладывался не на map, а на Date.parse. Проанализировал что делает Date.parse из строки приводя к виду
  iso8601, получилось что метод совершенно лишний, происходило преобразование из строки в строку того же вида.
  Убрал. Получил следующий результат ассимптотики:

  3000000: 24 sec;
  
- На полновый выборке скорость выполнения достигла 27 секунд. Результат достигнут.

### Ваша находка №7
- запустил StackProf в режиме callgrind (скрипт запуска и результат в /6-ruby-stackprof/).
  В выводе stackprof    
  
      11791  (48.1%)       11791  (48.1%)     (marking)
      3483  (14.2%)        3483  (14.2%)     Array#include?   

- Array#include? данный метод я менял вместо метода all? в находке №4, проанализировал скрипт и понял, что можно от него вообще отказаться,
  если перенести формирование уникальный браузеров и браузеров в общий с users цикл по sessions, а уникальность 
  посчитать методом uniq
  
- Программа для полного входного файла выполнилась за 21 секунду.

- Измерил линейность. Можно сказать (с натяжкой), что 500 тыс строк добавляет ~5 сек расчета.

  500000: 2 sec;
  
  1000000: 5 sec;
  
  1500000: 9 sec;
  
  2000000: 14 sec;
  
  2500000: 19 sec;
  
  3000000: 20 sec;


## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*

