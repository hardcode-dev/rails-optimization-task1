# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решила исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумала использовать такую метрику: беру из большого файла некоторое количесво строк, где-то на чуть больше секунды работы, и стараюсь улучшить в два раза, поднимаю количество строк и т.д. В итоге большой файл должен обработаться за 30 секунд.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроила эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений

Вот как я построила `feedback_loop`:
- Подготовила несколько txt-файлов с разным количеством строк
- добавила аргумент `file` в метод `work` для удобства
- Подготовила файлики с бенчмарками
- Подготовила перформенс тест для 'data6400.txt' perform_under(1).sec (это для loop №1, буду увеличивать размер файлика)
- вынесла в методы несколько блоков кода из `work` перед первым циклом, чтобы точнее локализировать точку роста.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовалась
- бенчмарком, пыталась определить асимптотику через зависимость ips от к-ва строк в файле, с GC выходило что-то похожее на експоненту
- библиотекой 'ruby-prof'

Вот какие проблемы удалось найти и решить

### Ваша находка №1 - метод `select` внутри метода `each`
- RubyProf::Grapf, RubuProf::CallTree
- заменить `session.select` для каждого пользователя предварительным сбором сессий в хеш с ключами `session['user_id']`
- на файле 'data6400.txt' время из 1.33 сек. уменьшилось до 0.15 сек., ips от 0.7 до 5.2
- `Array#each` все еще в топе, `select` пропал, потому-что его нету больше

### Ваша находка №2 - `fill_users_and_sessions` метод вынесенный из `work`
41.10% (41.10%) Object#fill_users_sessions [1 calls, 1 total]
29.84% (29.84%) Object#collect_stats_from_users
21.29% (21.30%) Object#unique_browsers [1 calls, 1 total]
- RubyProf::CallStack report
- убрала лишние переменные и заменила `users = users + [...]` и `users << [...]`
- для 'data50_000.txt' время изменилось от 2.58 сек до 1.35 сек
- в новом отчете `fill_users_and_sessions` упал c 41% до 12%

### Ваша находка №3 - `Object#collect_stats_from_users`
44.58% (44.58%) Object#collect_stats_from_users
31.98% (31.98%) Object#unique_browsers
12.39% (12.39%) Object#fill_users_and_sessions
- RubyProf::CallStack report
- `collect_stats_from_users` вызывается несколько раз с блоками, оптимизировала  код в блоках:
1) убрала лишние `map`; 2) заменила конкатенацию на интерполяцию; 3) заменила регулярные выражения методом `include?`;
4) заметила, что дата выводится в неизменном виде, и убрала `Date.parse` (это больше всего повлияло)
- для 'data50_000.txt' время изменилось от 1.35 сек до 0.96
- `Object#collect_stats_from_users` упал с 45% до 24%

### Ваша находка №4 - `Object#unique_browsers`
44.96% (44.97%) Object#unique_browsers
24.41% (24.41%) Object#collect_stats_from_users
15.90% (15.90%) Object#fill_users_and_sessions
- RubyProf::CallStack report
- использовала метод `to_set`
- для 'data50_000.txt' время изменилось от 0.96 до 0.71
- `Object#unique_browsers` исчез из отчета

### Ваша находка №5 - `Object#collect_stats_from_users`
46.18% (46.18%) Object#collect_stats_from_users
24.71% (24.71%) Object#fill_users_and_sessions
- RubyProf::CallStack report
- Метод вызывается семь раз, убрала из `Object#collect_stats_from_users` генерацию ключа "имя-фамилия" и инициализацию хеша report['usersStats'].
- для 'data50_000.txt' время изменилось от 0.71 до 0.58
35.33% (35.33%) Object#collect_stats_from_users
30.36% (30.36%) Object#fill_users_and_sessions

'data100_000.txt'
### Ваша находка №6 - `Object#collect_stats_from_users`
46.18% (46.18%) Object#collect_stats_from_users
24.71% (24.71%) Object#fill_users_and_sessions
- RubyProf::CallStack report
- Заменила класс User страктом и по ходу было много рефакторинга, ожидала большого результата
- для 'data100_000.txt' время изменилось всего от чуть больше минуты до 0.91
41.18% (41.18%) Object#collect_stats_from_users  [7 calls, 7 total]
35.54% (35.54%) Object#fill_users_and_sessions [1 calls, 1 total]

'data_large.txt'
### Ваша находка №7 - `Object#collect_stats_from_users`
40.22% (40.22%) Object#collect_stats_from_users [7 calls, 7 total]
34.40% (34.41%) Object#fill_users_and_sessions [1 calls, 1 total]
- RubyProf::CallStack report
- `Object#collect_stats_from_users` вызывается 7 раз, в двух случаях `map` идет по полю для времени сессий
и в трех - по браузерам сессий, объединила, теперь не 7 раз, а 4; и рефакторинг по ходу.
- для 'data_large.txt' время изменилось oт 51 сек до 45 сек. `Object#collect_stats_from_users` упал ниже `Object#fill_users_and_sessions`:
41.74% (41.74%) Object#fill_users_and_sessions [1 calls, 1 total]
31.09% (31.09%) Object#collect_stats_from_users [4 calls, 4 total]

'data_large.txt'
### Ваша находка №8 - `Object#fill_users_and_sessions`
41.74% (41.74%) Object#fill_users_and_sessions [1 calls, 1 total]
31.09% (31.09%) Object#collect_stats_from_users [4 calls, 4 total]
- RubyProf::CallStack report
- Добавила библиотеку 'oj', убрала лишние поля, которые парсились и сохранялись, лишние переменные. Взялась за `collect_stats_from_users`, убрала многократные его вызовы, сформировала единый хеш для `report['usersStats']` и аналогичный для общей информации, опять убрала лишние переменные. Время выполнения упало до 26 секунд, насколько возможно, навела красоту, заметила еще пару лишних переменных.
- для 'data_large.txt' время изменилось oт 45 сек. до 27.7 сек! Больше всего повлияло использование `oj` для конвертации в json - около 8 секунд, и работа с `collect_stats_from_users` - уменьшение прохождений по массивам и ее вызовов.

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с "бесконечности" до 28 секунд и уложиться в заданный бюджет. С отключенным GC программа выполняется за 16 секунд, но подвисают все процессы на несколлько секунд.

Трудно было контролировать себя и заниматься только точкой роста, старалась и это спасало от хаоса. Попробовала несколько отчетов ryby-prof, выбрала один, было достаточно чтобы увидеть проблемное место, дополнительно пользовалась бенчмарком и rspec/performance. Убедилась в еффективности некоторых методов, некоторые удивляли, ребята уже писали об этом. Еще выводы: Struct быстрее, чем класс и, у меня получилось, чем хеш, изобилие переменных - не хорошо, перебор с переборами массивов - совсем плохо.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы использовала библиотеку rspec/performance
  it { expect { work('data_large.txt') }.to perform_under(30).sec }

Но тест выше долго выполняется, я бы оставила следующий вариант:
  it { expect { work('data100_000.txt') }.to perform_under(0.8).sec }
это уже в окончательном варианте с запасом.

Задание было challenging, спасибо!
