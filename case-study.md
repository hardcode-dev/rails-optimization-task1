
## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался 
- `ruby-prof` в режиме `Flat`
- `ruby-prof` в режиме `Graph`
- `ruby-prof` в режиме `CallStack`
- `stackprof` с помощью `speedscope.app`

Вот какие проблемы удалось найти и решить


## Подготовка 
- простой рефакторинг кода, чтобы отделить тесты\классы
- подготовка фикстур

### Фиксация точки начала
Задача: оценить время исполнения в зависимости от объема входных данных.

Инструмент: Benchmark

| №   | Кол-во строк | Итоговое время с GC | Итоговое время без GC |
|-----|--------------|---------------------|-----------------------|
| 1   | 1000         | 0.024               | 0.019                 |
| 2   | 2000         | 0.055               | 0.055                 |
| 3   | 4000         | 0.19                | 0.189                 |
| 4   | 8000         | 0.671               | 0.67                  |
| 5   | 16000        | 2.45                | 2.611                 |
| 6   | 32000        | 10.279              | 20.011                |
| 7   | 64000        | 65.972              | 119.576               |

Выводы: 
- Скорость обработки растет нелинейно ~ n^2.
- Для быстрого фидбек-лупа удобнее работать с объемами **50-60 тыс.строк**

Результаты этапа: 
- написаны тесты на производительность (защита от деградации)

### Настройка инструментария

Задача: оценить различные инструменты и подготовить рабочую область.

Инструменты:
- RubyMine **rbspy**
- **ruby-prof** (Flat/Graph/Callstack)
- **stackprof** ([](http://speedscope.app))

|                      | Метод        | %     | Примечание |
|----------------------|--------------|-------|------------|
| rbspy                | select       | 89.2  |            |
| ruby-prof/Flat       | Array#select | 83.13 |            |
| ruby-prof/Graph      | Array#select | 83.81 |            |
| ruby-prof/Callstack  | Array#select | 83.81 |            |
| stackprof            | Array#each   | 90.0  |            |

Выводы: 
- `rbspy` в RubyMine практически нечитаем ( длинные breadcrumbs и сложно идентифицировать методы)
- `ruby-prof` (быстрый и удобночитаемый, но нужно использовать все одновременно)
- `stackprof` хорошо отображает последовательности но неудобно каждый раз лазить на сайт и обновлять графики


### Итерация №1
- Все отчеты показали главную точку роста в `Array#select` ~ 83 %
Проблема: для каждого юзера полностью пробегается массив с сессиями

Решение:
- пробежаться один раз по массиву сессий и создать накопительный хеш. 
- пробежаться один раз по массиву пользователей и создать их на основании накопительного хеша

Что изменилось:
`Array#select` ~ 33 %

| №   | Строк | Было   | Стало  |
|-----|-------|--------|--------|
| 1   | 64000 | 65.972 | 1.431  |

----------------------

### Итерация №2
Точки роста: 
- Array#each(Parser#collect_stats_from_users | Date) = 38.34%. 
- Array#each(Парсинг уникальных барузеров) = 34 %

Решение:
- Парсить браузеры совместно с парсингом сессий (в одной итерации) + Использовать Set
- Убрать двойной map для парсинга Даты

Что изменилось:

| №   | Строк | Было    | Стало  |
|-----|-------|---------|--------|
| 1   | 64000 | 1.431   | 1.279  |

----------------------

### Итерация №3

Точка роста: Array#each ( Парсинг строк) = 48.35%
Решение: Заменить File.read().each на File.foreach, который не загружает в память фал целиком.

Что изменилось:

| №   | Строк | Было    | Стало  |
|-----|-------|---------|--------|
| 1   | 64000 |  1.279  | 0.711  |

----------------------

### Итерация №4

Точка роста: Parser#collect_stats_from_users (Array#each)  = 20.68%
Решение: 
- Совмести все collect_stats_from_users
- заменить в хешах строки на символы
- Хранить сессии в Struct
- конвертировать атрибуты сессии при ее создании (to_i, upcase)
- не парсить дату в iso8601, т.к. данные уже в этом формате
- использовать start_with?

Что изменилось:
- зависимость перешла в линейную ( подтверждено тестами)

| №   | Строк | Было    | Стало |
|-----|-------|---------|-------|
| 1   | 64000 |  0.711  | 0.266 |

ВЕСЬ ФАЙЛ (3_250_940 строк)

| №   | Стало |
|-----|-------|
| 1   | 22,5  |

----------------------

### Итерация №5

Точка роста: Array#each(парсинг сессий) = 18,55%
Решение: 
- Отказаться от Struct и Set в пользу простых хеша и массива ( протестированно в benchmark)
- совместить парсинг сессий и сортировку по юзерам
- не хранить session_id, т.к. не используется
- 

Что изменилось:
- выиграл еще несколько секунд на мелочах ( ввел отдельные счетчики и накопители )

| №   | Строк | Было    | Стало |
|-----|-------|---------|-------|
| 1   | 64000 |  0.266  | 0.184 |

ВЕСЬ ФАЙЛ (3_250_940 строк)  

| №   | Стало                              |
|-----|------------------------------------|
| 1   | 24.15  ( 9.8 сек. с выключенным GC |

----------------------

### Итерация №6

Точка роста: File.write
Решение:
- Использовать сериализатор для json

| №   | Стало                             |
|-----|-----------------------------------|
| 1   | 22.5  ( 9.8 сек. с выключенным GC |

## Результаты
В результате проделанной оптимизации файл в 3,2 млн строк был обработан за ~22.5 секунды.



