# Case-study оптимизации

## Актуальная проблема

Необходимо обработывать файлы с данными, чуть больше ста мегабайт за время не превышающее 30 секунд.

Имеется готовое решение успешно работающее на файлах размером в несколько мегабайт.
Но для большого файла программа работала слишком долго, без прогноза необходимого времени.

## Формирование метрики

Для анализа влияния изменений кода на быстродействие программы выбрана метрика: 
время работы программы на различных объемах данных.

## Гарантия корректности работы оптимизированной программы

Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Подготовительный этап

- Подготовлены наборы данных различной длины (с двухкратным увеличением количества строк)
- Добавлен скрипт запускающий benchmark для замера времени работы алгоритма на различном размере данных

## Feedback-Loop

- Настраиваем и запускаем выбранные инструменты профилирования, анализируем их работу для нахождения главной точки роста.
  - При недостатке данных выбираем другие инструменты профилирования, повторяем замеры и анализ.
- Вносим небольшие изменения в проблемный участок кода для оптимизации.
- Проверяем стабильность программы запуском теста.
  - При проваленном тесте возвращаемся к исправлению кода.
- Проверяем результат оптимизиции на основе изменений выбранной метрики.
  - При отсутствии положительных изменений возвращаемся к исправлению кода.
- Фиксируем результат в системе контроля версий.
- Фиксируем время прохождения цикла Feedback-Loop для посдующей фиксации в текущем документе
- Для удобства настраиваем скрипт на последовательный запуск данных инструментов.

Итог: один проход по Feedback-Loop занимал в от нескольких секунд до нескольких минут в зависимости от размера тестовых данных.

## Главные точки роста

Для того, чтобы найти "точки роста" были использованы:

- ruby-prof
  - wall time report
    - graph_html

Вот какие проблемы удалось найти и решить

### Вызов select внутри цикла

Метод select вызывался на одном и том же массиве на каждую итерацию основного цикла

- какой отчёт показал главную точку роста
  - ruby prof: wall time
- как вы решили её оптимизировать
  - предварительная группировка данных массива
- как изменилась метрика

  | количество строк | было   | стало |
  |------------------|--------|-------|
  | 1k               | 14ms   | 16ms  |
  | 2k               | 45ms   | 33ms  |
  | 4k               | 166ms  | 53ms  |
  | 8k               | 606ms  | 117ms |
  | 16k              | 2431ms | 308ms |
  | 32k              | 11.5s  | 604ms |
  | 64k              | 57s    | 1.8s  |
  | 128k             | 3.7m   | 6.7s  |
  | 256k             | 12.8m  | 24.5s |
  | 3250940          | ? *    | ?     |
  (*) предположительное значение 27 часов учитывая предположительную квадратичную сложность,
      но результат исправленного кода всё равно не позволил дождаться результата за разумное время,
      так как начиная с определенного размера файла время обработки снова налало увеличиваться нелинейно.
      Отключение garbage collector не позволило оценить успешность улучшение основного алгоритма (не хватило памяти)

- исправленная проблема перестала быть главной точкой роста?
  - да

## На больших размерах файла 40% времени уходит на работу garbage collection

- какой отчёт показал главную точку роста
  - stackprof: wall time
- как вы решили её оптимизировать
  - решил отложить эту проблему на более поздний этап

## На больших размерах данных 40% полезной работы уходит на сложение массивов

Сложение массивов создаёт новый массив копируя в него данные из обоих массивов.
В текущей программе это не требуется и достаточно просто добавлять элементы в существующие массивы

- какой отчёт показал главную точку роста
  - ruby prof: wall time
- как вы решили её оптимизировать
  - замена конструкции `a = a + [b]` на `a << b`
- как изменилась метрика
 
  | количество строк | было  | стало |
  |------------------|-------|-------|
  | 1k               | 16ms  | 8ms   |
  | 2k               | 33ms  | 15ms  |
  | 4k               | 53ms  | 29ms  |
  | 8k               | 117ms | 67ms  |
  | 16k              | 308ms | 117ms |
  | 32k              | 604ms | 268ms |
  | 64k              | 1.8s  | 561ms |
  | 128k             | 6.7s  | 1.1s  |
  | 256k             | 24.5s | 2.6s  |
  | 3250940          | ?     | 51s   |

- исправленная проблема перестала быть главной точкой роста?
  - да

## На определенном размере файла большую часть времени начала занимать проверка уникальности имён браузеров

- какой отчёт показал главную точку роста
  - ruby prof: wall time
- как вы решили её оптимизировать
  - Замена ручной проверки уникальности элементов на использование класса `Set`
- как изменилась метрика
 
  | количество строк | было  | стало |
  |------------------|-------|-------|
  | 1k               | 8ms   | 13ms  |
  | 2k               | 15ms  | 17ms  |
  | 4k               | 29ms  | 21ms  |
  | 8k               | 67ms  | 45ms  |
  | 16k              | 117ms | 95ms  |
  | 32k              | 268ms | 193ms |
  | 64k              | 561ms | 423ms |
  | 128k             | 1.1s  | 923ms |
  | 256k             | 2.6s  | 2.2s  |
  | 3250940          | 51s   | 47s   |

- исправленная проблема перестала быть главной точкой роста?
  - да

## Значительное время занимал парсинг дат вызываемый в цикле

- какой отчёт показал главную точку роста
  - ruby prof: wall time
- как вы решили её оптимизировать
  - Замена `Date.parse(d)` на `Date.strptime(d, '%Y-%m-%d')`
- как изменилась метрика
 
  | количество строк | было  | стало |
  |------------------|-------|-------|
  | 1k               | 13ms  | 11ms  |
  | 2k               | 17ms  | 7ms   |
  | 4k               | 21ms  | 15ms  |
  | 8k               | 45ms  | 29ms  |
  | 16k              | 95ms  | 68ms  |
  | 32k              | 193ms | 126ms |
  | 64k              | 423ms | 300ms |
  | 128k             | 923ms | 674ms |
  | 256k             | 2.2s  | 1.6s  |
  | 3250940          | 47s   | 42s   |

- исправленная проблема перестала быть главной точкой роста?
  - нет

## Парсинг и обработка дат всё ещё занимает значительно время

- какой отчёт показал главную точку роста
  - ruby prof: wall time
- как вы решили её оптимизировать
  - добавление кэширование, так как по идее даты сессий должны часто совпадать и нет смысла парсить их повторно
    `Hash.new { |h, date_string| h[date_string] = Date.strptime(date_string, '%Y-%m-%d') }`
- как изменилась метрика

  | количество строк | было  | стало |
  |------------------|-------|-------|
  | 1k               | 11ms  | 25ms  |
  | 2k               | 7ms   | 7ms   |
  | 4k               | 15ms  | 14ms  |
  | 8k               | 29ms  | 28ms  |
  | 16k              | 68ms  | 57ms  |
  | 32k              | 126ms | 118ms |
  | 64k              | 300ms | 276ms |
  | 128k             | 674ms | 663ms |
  | 256k             | 1.6s  | 1.8s  |
  | 3250940          | 42s   | 35s   |

- исправленная проблема перестала быть главной точкой роста?
  - да, но при время обработки файла изменилось незначительно,
    вероятно из-за увеличения количества аллокаций, откалил изменения

## 50% времени уходит на циклы в `collect_stats_from_users`

В основном это обработка сессий пользователя, проход по сессиям осуществляется несколько раз, хотя достаточно одного

- какой отчёт показал главную точку роста
  - ruby prof: wall time
- как вы решили её оптимизировать
  - в 2 этапа
    - убрал повторные вызовы `collect_stats_from_users`
    - частично убрал повторные проходы по сессиям
- как изменилась метрика

  первый этап

  | количество строк | было  | стало |
  |------------------|-------|-------|
  | 1k               | 25ms  | 13ms  |
  | 2k               | 7ms   | 7ms   |
  | 4k               | 14ms  | 13ms  |
  | 8k               | 28ms  | 27ms  |
  | 16k              | 57ms  | 55ms  |
  | 32k              | 118ms | 117ms |
  | 64k              | 276ms | 239ms |
  | 128k             | 663ms | 648ms |
  | 256k             | 1.8s  | 1.4s  |
  | 3250940          | 35s   | 30s   |


## Результаты

Удалось обработать файл с данными.
Удалось улучшить целевую метрику системы и уложиться в заданный бюджет.
было:  *27 часов*
стало: *TODO сек*

TODO: дополнительные достижения

## Защита от регрессии производительности

Для защиты от потери достигнутого прогресса при дальнейших изменениях программы были добавлены 2 теста:

- TODO: На линейное время выполнение алгоритма
- TODO: На выполнение работы программы в пределах заданных требований по времени работы

