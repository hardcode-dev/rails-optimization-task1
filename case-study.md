# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: *время полной обработки файла в секундах*

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *2.6 секунды*

Вот как я построил `feedback_loop`:
  1. Для проверки правильности отчета использовал минимальный набор данных (10 000).
  2. Использовал профилировщик для поиска точки роста
  3. Рефакторил код
  4. Повторно проверял результат профилировщика
  5. Запускал общий тест чтобы проверить что ничего не сломал
  6. В случае успешного результата писал тест
  7. Коммитил результат

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался:
  1. `rbspy` (показывает только запущенный процесс)
  2. `ruby-prof: flat`
  3. `ruby-prof: graph html`
  4. `ruby-prof: CallTree`

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- `ruby-prof: flat` - Показал что точка роста метод `Array#select` там 87.96% времени находится.
- решил сгрупировать сесии по пользователям и вынести их с блока `each`
- улучшилась почти в 7 раз, с 2.6 sec. => 400 ms
- `ruby-prof: flat` - Показал что точка роста изменилась, теперь новая ТР метод `Array#each` (40.65%) и `Array#all?` (25.92%).

### Ваша находка №2
- `ruby-prof: graph html` - Показал что точка роста изменилась, теперь новая ТР метод `Array#each` (40.65%) и `Array#all?` (25.92%).
- Переписал вариант выбора уникальных браузеров
- Метрика немного улучшилась с 400 ms => 340 ms
- `ruby-prof: graph html` - Показал что точка роста изменилась, теперь `Array#each` (54.94%) и `Array#map` (11.86%).

### Ваша находка №3
- `ruby-prof: CallTree` - Показал что точка роста метод `Array#each` (54.94%) и `Array#map` (11.86%) => `Date#parse`.
- переписал метод `collect_stats_from_user`, решил вызывать его в блоке `each` для пользователей, избавился от `Date#parse` так как он здесь лишний
- Метрика немного улучшилась для 10 000 записей с 340 ms => 310 ms решил проверить на большем количестве для 50 000 вкладывается в 5 сек
- `ruby-prof: CallTree` - Показал что точка роста метод `Array#each` увеличелась (60.28%) и `Array#map` уменьшился (8.19%).

### Ваша находка №4
- `ruby-prof: CallTree` - Показал что точка роста метод `Array#each` увеличелась (60.28%) и `Array#map` уменьшился (8.19%).
- решил логику по груперовке сессий по пользователю делать при парсинге файла
- Метрика улучшилась для 10 000 записей с 340 ms => 45 ms, для 100 000 вкладывается в 550 ms
- `ruby-prof: CallTree` - Показал что точка роста метод `Array#each` пропала, теперь главный метод програмы `work` (10.10%).

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *2.6 sec до 45 ms* и уложиться в заданный бюджет.

*Также решил избавится от класса `User` так как пользи от него никакой а от GC "страдает"*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *написал тест*

