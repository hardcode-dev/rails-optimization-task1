# Case-study оптимизации

## Актуальная проблема

Необходимо обработывать файлы с данными, чуть больше ста мегабайт за время не превышающее 30 секунд.

Имеется готовое решение успешно работающее на файлах размером в несколько мегабайт.
Но для большого файла программа работала слишком долго, без прогноза необходимого времени.

## Формирование метрики

Для анализа влияния изменений кода на быстродействие программы выбрана метрика: 
время работы программы на различных объемах данных.

## Гарантия корректности работы оптимизированной программы

Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Подготовительный этап

- Подготовлены наборы данных различной длины (с двухкратным увеличением количества строк)
- Добавлен скрипт запускающий benchmark для замера времени работы алгоритма на различном размере данных

## Feedback-Loop

- Настраиваем и запускаем выбранные инструменты профилирования, анализируем их работу для нахождения главной точки роста.
  - При недостатке данных выбираем другие инструменты профилирования, повторяем замеры и анализ.
- Вносим небольшие изменения в проблемный участок кода для оптимизации.
- Проверяем стабильность программы запуском теста.
  - При проваленном тесте возвращаемся к исправлению кода.
- Проверяем результат оптимизиции на основе изменений выбранной метрики.
  - При отсутствии положительных изменений возвращаемся к исправлению кода.
- Фиксируем результат в системе контроля версий.
- Фиксируем время прохождения цикла Feedback-Loop для посдующей фиксации в текущем документе
- Для удобства настраиваем скрипт на последовательный запуск данных инструментов.

Итог: одна итерация по Feedback-Loop занимала в от нескольких секунд 
      на начальном этапе до нескольких минут на поздих этапах в зависимости
      от размера тестовых данных.

## Главные точки роста

Для того, чтобы найти "точки роста" были использованы:

- ruby-prof
  - wall time report
    - graph_html
- stackprof
  - wall time report
    - flamegraph
    - text

Вот какие проблемы удалось найти и решить

### Вызов select внутри цикла

Метод select вызывался на одном и том же массиве на каждую итерацию основного цикла

- какой отчёт показал главную точку роста
  - ruby prof: wall time
- как вы решили её оптимизировать
  - предварительная группировка данных массива
- как изменилась метрика

  | количество строк | было   | стало |
  |------------------|--------|-------|
  | 1k               | 14ms   | 16ms  |
  | 2k               | 45ms   | 33ms  |
  | 4k               | 166ms  | 53ms  |
  | 8k               | 606ms  | 117ms |
  | 16k              | 2431ms | 308ms |
  | 32k              | 11.5s  | 604ms |
  | 64k              | 57s    | 1.8s  |
  | 128k             | 3.7m   | 6.7s  |
  | 256k             | 12.8m  | 24.5s |
  | 3250940          | ? *    | ?     |
  (*) предположительное значение 27 часов учитывая предположительную квадратичную сложность,
      но результат исправленного кода всё равно не позволил дождаться результата за разумное время,
      так как начиная с определенного размера файла время обработки снова налало увеличиваться нелинейно.
      Отключение garbage collector не позволило оценить успешность улучшение основного алгоритма (не хватило памяти)

- исправленная проблема перестала быть главной точкой роста?
  - да

## На больших размерах файла 40% времени уходит на работу garbage collection

- какой отчёт показал главную точку роста
  - stackprof: wall time
- как вы решили её оптимизировать
  - решил отложить эту проблему на более поздний этап

## На больших размерах данных 40% полезной работы уходит на сложение массивов

Сложение массивов создаёт новый массив копируя в него данные из обоих массивов.
В текущей программе это не требуется и достаточно просто добавлять элементы в существующие массивы

- какой отчёт показал главную точку роста
  - ruby prof: wall time
- как вы решили её оптимизировать
  - замена конструкции `a = a + [b]` на `a << b`
- как изменилась метрика
 
  | количество строк | было  | стало |
  |------------------|-------|-------|
  | 1k               | 16ms  | 8ms   |
  | 2k               | 33ms  | 15ms  |
  | 4k               | 53ms  | 29ms  |
  | 8k               | 117ms | 67ms  |
  | 16k              | 308ms | 117ms |
  | 32k              | 604ms | 268ms |
  | 64k              | 1.8s  | 561ms |
  | 128k             | 6.7s  | 1.1s  |
  | 256k             | 24.5s | 2.6s  |
  | 3250940          | ?     | 51s   |

- исправленная проблема перестала быть главной точкой роста?
  - да

## На определенном размере файла большую часть времени начала занимать проверка уникальности имён браузеров

- какой отчёт показал главную точку роста
  - ruby prof: wall time
- как вы решили её оптимизировать
  - Замена ручной проверки уникальности элементов на использование класса `Set`
- как изменилась метрика
 
  | количество строк | было  | стало |
  |------------------|-------|-------|
  | 1k               | 8ms   | 13ms  |
  | 2k               | 15ms  | 17ms  |
  | 4k               | 29ms  | 21ms  |
  | 8k               | 67ms  | 45ms  |
  | 16k              | 117ms | 95ms  |
  | 32k              | 268ms | 193ms |
  | 64k              | 561ms | 423ms |
  | 128k             | 1.1s  | 923ms |
  | 256k             | 2.6s  | 2.2s  |
  | 3250940          | 51s   | 47s   |

- исправленная проблема перестала быть главной точкой роста?
  - да

## Значительное время занимал парсинг дат вызываемый в цикле

- какой отчёт показал главную точку роста
  - ruby prof: wall time
- как вы решили её оптимизировать
  - Замена `Date.parse(d)` на `Date.strptime(d, '%Y-%m-%d')`
- как изменилась метрика
 
  | количество строк | было  | стало |
  |------------------|-------|-------|
  | 1k               | 13ms  | 11ms  |
  | 2k               | 17ms  | 7ms   |
  | 4k               | 21ms  | 15ms  |
  | 8k               | 45ms  | 29ms  |
  | 16k              | 95ms  | 68ms  |
  | 32k              | 193ms | 126ms |
  | 64k              | 423ms | 300ms |
  | 128k             | 923ms | 674ms |
  | 256k             | 2.2s  | 1.6s  |
  | 3250940          | 47s   | 42s   |

- исправленная проблема перестала быть главной точкой роста?
  - нет

## Парсинг и обработка дат всё ещё занимает значительно время

- какой отчёт показал главную точку роста
  - ruby prof: wall time
- как вы решили её оптимизировать
  - добавление кэширование, так как по идее даты сессий должны часто совпадать и нет смысла парсить их повторно
    `Hash.new { |h, date_string| h[date_string] = Date.strptime(date_string, '%Y-%m-%d') }`
- как изменилась метрика

  | количество строк | было  | стало |
  |------------------|-------|-------|
  | 1k               | 11ms  | 25ms  |
  | 2k               | 7ms   | 7ms   |
  | 4k               | 15ms  | 14ms  |
  | 8k               | 29ms  | 28ms  |
  | 16k              | 68ms  | 57ms  |
  | 32k              | 126ms | 118ms |
  | 64k              | 300ms | 276ms |
  | 128k             | 674ms | 663ms |
  | 256k             | 1.6s  | 1.8s  |
  | 3250940          | 42s   | 35s   |

- исправленная проблема перестала быть главной точкой роста?
  - да, но при время обработки файла изменилось незначительно,
    вероятно из-за увеличения количества аллокаций, откалил изменения

## Попытка уменьшить время работы Garbage Collection

Garbage collection теперь выполняется около 50% времени

- какой отчёт показал главную точку роста
  - stackprof: wall time
- как вы решили её оптимизировать
  - попытался уменьшить количество создаваемых объектов в наиболее часто вызываемых местах
- как изменилась метрика
  - смог уменьшить время обработки большого файла до 28 секунд, но решил отменить изменения,
    так как не увидел значительного влияние на время работы сборщика мусора,
    скорее всего болшее влияние имели косвенные причины.

## 50% полезной работы уходит на циклы в `collect_stats_from_users`

В основном это обработка сессий пользователя, проход по сессиям осуществляется несколько раз, хотя достаточно одного

- какой отчёт показал главную точку роста
  - ruby prof: wall time
- как вы решили её оптимизировать
  - в 2 этапа
    - убрал повторные вызовы `collect_stats_from_users`
    - частично убрал повторные проходы по сессиям
- как изменилась метрика

  первый этап

  | количество строк | было  | стало |
  |------------------|-------|-------|
  | 1k               | 25ms  | 13ms  |
  | 2k               | 7ms   | 7ms   |
  | 4k               | 14ms  | 13ms  |
  | 8k               | 28ms  | 27ms  |
  | 16k              | 57ms  | 55ms  |
  | 32k              | 118ms | 117ms |
  | 64k              | 276ms | 239ms |
  | 128k             | 663ms | 648ms |
  | 256k             | 1.8s  | 1.4s  |
  | 3250940          | 35s   | 30s   |

  второй этап

  | количество строк | было  | стало |
  |------------------|-------|-------|
  | 1k               | 13ms  | 12ms  |
  | 2k               | 7ms   | 6ms   |
  | 4k               | 13ms  | 11ms  |
  | 8k               | 27ms  | 22ms  |
  | 16k              | 55ms  | 44ms  |
  | 32k              | 117ms | 95ms  |
  | 64k              | 239ms | 199ms |
  | 128k             | 648ms | 451ms |
  | 256k             | 1.4s  | 1.1s  |
  | 3250940          | 30s   | 23s   |

## Результаты

Удалось обработать файл с данными.
Удалось улучшить целевую метрику системы и уложиться в заданный бюджет.
- было:  27 часов
- стало: 23 секунд

## Защита от регрессии производительности

Для защиты от потери достигнутого прогресса при дальнейших изменениях программы были добавлены 2 теста:

- На линейное время выполнение алгоритма
- На выполнение работы программы в пределах заданных требований по времени работы

