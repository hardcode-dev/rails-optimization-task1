# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: время выполнения программы на файле из 20 000 строк.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за ~1 минуту.

Вот как я построил `feedback_loop`:

Встроил в программу progressbar для возможности визуального контроля за прогрессом выполнения
Зафиксировал время выполнения исходной программы на файле из 20 000 строк (около 3.3 с)
Использовал инструменты профилирования для выявления точек роста
При выявлении точки роста вносил изменения и убеждался в том, что они позитивно влияют на выбранную метрику
По мере ускорения выполнения программы увеличивал объём тестового файла

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался ruby-prof и rbspy.

Вот какие проблемы удалось найти и решить

### Находка №1

ruby-prof в режиме flat показал точку роста при формировании списка сессий пользователя с помощью `Array#select`.
Я решил провести оптимизацию путём замены массива сессий на хэш с ключом в виде id пользователя и значением - списком сессий с этим id.
Все фрагменты кода, обращающиеся к массиву sessions также переписал с учётом новой специфики и убедился, что тест, поставляемый с программой, не падает.
Согласно новому отчёту профилировщика, присвоение сессий пользователям перестало быть точкой роста.

### Находка №2

Так как время выполнения программы значительно уменьшилось на выбранном объёме данных, решил его увеличить до 100 000 строк.
Время выполнения с этим объёмом увеличилось до ~3.5 с.
ruby-prof в формате CallStack показал точку роста при подсчёте уникальных браузеров методом `Array#all?`.
Время выполнения уменьшилось до ~2.7 с, подсчёт уникальных браузеров перестал быть точкой роста.

### Находка № 3
В call tree увидел, что значительное время уходит на парсинг даты.
Дата и так в нужном формате, поэтому убрал парсинг и заменил `#reverse` на `#reverse!`, время выполнения уменьшилось до ~2.4 с

### Находка № 4
Call tree показало точку роста при проходе по юзерам (`Array#each`).
Я оптимизировал этот момент путём переделки массива юзеров в хэш и обработки их в одном цикле с сессиями (по мере нахождения новые сессии добавляются к юзеру по id (ключ хэша))
От хэша с сессиями при этом избавился из-за избыточности.
Время выполнения при текущем объеме данных уменьшилось до ~1.1 с.

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 3.3 секунд до 0.15 секунд и уложиться в заданный бюджет.
Обработка полного файла (data_large.txt) занимает около 24 секунд.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы я добавил тест на производительность при обработке файла из 20 000 строк и зафиксировал в нём достигнутый результат.

