# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: проверять профилировщиком небольшой объем тестовых данных, постепенно увеличивая объем этих данных, таким образом можно выявлять проблемные методы, которые влияют на скорость выполнения программы

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Проверка шаблонизаторами небольших объемов тестовых данных, ответ должен приходить через несколько секунд

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался ruby-prof(flat и graph_html) и stackprof

Вот какие проблемы удалось найти и решить

### 1. идет дважды split строки из файла
- ruby-prof, flat
- Изменить методы парсинга сессий и пользователей, чтобы split на строку был только один раз
- Количество данного вида операций сократилось в 2 раза
- На данном этапе данный метод не является главное точкой роста

### 2. select на массиве сессий
- ruby-prof, graph
- перед блоком группировать сессии по user_id
- Сложность алгоритма поиска сессий пользователя сейчас составляет О(1)
- На данном этапе данный метод не является главное точкой роста

### 3. Метод #collect_stats_from_users
- stackprof, ruby-prof, graph + flat
- Переписать метод, избавиться в методе от each. Вызывать метод в блоке each, где создается user_object. Так же выполнить рефакторинг кода, который несколько раз вызывает map на один массив
- скорость обработки файла data_large на процессоре intel core i7 3-го поколения составляет 80 с., предполагаю, что на более современном процессоре этот показатель может быть лучше.
- На данном этапе данный метод не является главное точкой роста

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
