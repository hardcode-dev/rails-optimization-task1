# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: 
сколько ips выдает программа на файле из 1000 строк
бюджет на метрику не меньше 3251ips
до правок метрика показывала 32.662 (± 2.4%) i/s 

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за несколько секунд

Вот как я построил `feedback_loop`:
- вынес в отдельный файл тест на корректность кода, включил автопрогон теста при изменениях в IDE либо из консоли `rspec task-1_spec.rb` 
- в отдельный файл вынес прогон нескольких профайлеров с разными отчетами + вычисление метрикию запуск из консоли `ruby app.rb`
- сам `feedback_loop` выглядит так: прогон профайлеров => выдвижение гипотезы => подсветка корректности кода => еще прогон профайлеров с метриками => фиксация результата в тесте 

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался RubyProf::WALL_TIME c принтерами GraphHtmlPrinter, CallStackPrinter
Попробовал все, но эти выделил как основные

Вот какие проблемы удалось найти и решить

### Находка №1 
- RubyProf::WALL_TIME c принтером GraphHtmlPrinter показал что 89% времени занимает Array#select
- В этом месте select перебирает все записи сессий для каждого юзера. Это порождает O(N^2)
  Поэтому решено переписать код так, чтобы сессии групировались по юзерам за один проход  
- после правок метрика показала 62.835  (± 0.9%) i/s, что в два раза быстрее чем было( 32.662 (± 2.4%) ) 
- из того же отчета пропала запись об Array#select(потому что мы его заменили на другой метод) в топ вышли другие методы

### Ваша находка №2
- RubyProf::WALL_TIME c принтером CallStackPrinter показал что 30% времени занимает Array#all? при подсчете уникальных браузеров
  выделить проблемый all? удалось вынося все all? в именованные методы
- В этом месте для каждой сессии перебирается список уникальных браузеров для поиска новых уникальных браузеров. Это порождает O(N^2)
  Поэтому было решено заменить Array на Set для списка браузеров,и убрать проверку на уникальность
- после правок метрика показала  87.038  (± 1.7%) i/s
- отчет профилировщика изменился. метод пропал из топа, что говорит о том что он занимает меньше 1%

### Ваша находка №3
- RubyProf::WALL_TIME c принтером CallStackPrinter показал что 48% времени занимает Array#each при сборе статистики по юзерам
- для каждого вида статистики(их 7 видов) мы проходим по всему списку юзеров.
  пробуем избежать этого собирая всю статистику в одном блоке 
- после правок метрика показала  101.098  (± 2.0%) i/s
- отчет профилировщика изменился незначительно.  Array#each стал занимать 40% времени

### Ваша находка №4
- RubyProf::WALL_TIME c принтером CallStackPrinter показал что 40% времени занимает Array#each при сборе статистики по юзерам
  внутри которого 40% времени это <Class::Date>#parse
- Поскольку даты в файле сохранены в формате iso8601, то сортируем без парсинга и сериализации обратно в iso8601
- после правок метрика показала  162.986  (± 0.8%) i/s
- в отчете профилировщика метод Array#each стал занимать 24% времени

### Ваша находка №5
- RubyProf::WALL_TIME c принтером CallStackPrinter показал что 65% времени занимает Array#split при проходе по файлу
  внутри которого больше всего времени занимал Array#split
- убрал лищний Array#split, там где есть уже готовые массивы
- после правок метрика показала  195.008  (± 0.8%) i/s 
- в отчете профилировщика метод Array#split по прежнему занимает 65% времени

### Ваша находка №6
- RubyProf::WALL_TIME c принтером CallStackPrinter показал что 14% времени занимает Array#map при сборе статистики по юзерам
- убираем многоступенчатые map, и собираем их в один метод чтобы избежать множественного прохода по одним и тем же данным
- после правок метрика показала  212.888  (± 1.3%) i/s 
- в отчете профилировщика метод Array#map стал занимать 7.7%

### Ваша находка №7
- RubyProf::WALL_TIME c принтером CallStackPrinter показал что 72% времени занимает Array#each
- Заменяем сложение массивов на вставку жлемента в массив при формировании списка пользователей и сессий
- после правок метрика показала  271.648  (± 0.9%) i/s 
  Мне начинает казаться что метрика была выбрана неудачно, потому что открытие файла на чтение тоже отимает время 
  и результаты не очень получается экстраполировать на большой файл.
  Принимаю за метрику парсинг файла на 100_000 строк. до изменений парсинг шел 4.16 сек После изменений 1.26 сек
- в отчете профилировщика метод Array#each стал занимать 41% времени

### Ваша находка №8
- RubyProf::WALL_TIME c принтером CallStackPrinter показал что 41% времени занимает Array#each
- Заменяем сложение массивов на вставку элемента в массив при формировании объектов юзеров
- После изменений ускорение в два раза
  Finish 100_000 in 0.55
  Finish 1_000_000 in 8.24
- в отчете профилировщика метод Array#each стал занимать 38% времени

### Ваша находка №9
- RubyProf::WALL_TIME c принтером CallStackPrinter показал что 37% времени занимает Object#collect_stats_from_users
- Для начала делаем рефакторинг чтобы видеть какие части метода больше всего съедают времени.
  Видим что половину времени уходит на Array#map, который состоит из сбора времени сессий, сбора браузеров, сбора дат  
  Идей по оптимизации не появилось  
- После изменений результат тот же
  Finish 100_000 in 0.54
  Finish 1_000_000 in 8.22
  Finish large in 35.12
- в отчете профилировщика появились названия для отдельных map но в целом отчет тот же

### Ваша находка №10
- Поскольку идей для оптимизации двух топовых частей Array#each и Object#collect_stats_from_users у меня не появилось
  Я решил обратить внимание на третий большой кусок это  Array#map на который приходится 8.5% времени 
- Если присмотрется к нему то увидим что там идет перечисление уникальных браузеров.
  Но у нас уже есть готовый список уникальных браузеров который я и использовал
- После изменений заметное ускорение и итоговый результат наконец уложился в метрику
  Finish 100_000 in 0.47
  Finish 1_000_000 in 6.9
  Finish large in 27.27
- На третье место в профилировщике вышел метод Class::IO#write

### Ваша находка №Final
- На третьем месте в профилировщике метод Class::IO#write у которой 15% времени
- Попробовал использовать гем oj для ускорения сериализации json при записи
- После изменений результата нет. Все осталось на своих местах
  Finish 100_000 in 0.46
  Finish 1_000_000 in 6.81
  Finish large in 27.91
- Все осталось на своих местах

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 261сек на файл из 100_000 строк до 0.46сек и уложиться в заданный бюджет.
Итоговый результат для исходного файла 27 секунд

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы написан тест
на максимальное время выполнения парсинга файла на 1000 строк


