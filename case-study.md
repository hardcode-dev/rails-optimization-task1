# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:

Время работы программы в секундах. В бюджет заложили 30 секунд. Файл с более чем 3 млн строк должен быть обработан за 30 или менее секунд.


## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 12 секунд (при первой итерации оптимизации, в дальнейшем оно уменьшилось).

Вот как я построил `feedback_loop`:

Для оценки будем использовать время выполнения программы. Но так как полный файл обрабатывать каждый раз не представляется возможным,
мы возьмем часть файла, объем которого, с одной стороны позволит измерять улучшение производительности,
а с другой стороны не заставить долго ждать при запуске тестов.

Всего в файле 3250940 строк. Возьмем первые 10 000 строк, выделим их в отдельный файл и будем использовать для тестирования.
Текущий алгоритм без оптимизации обрабатывает 10 000 строк за 2.4 секунды. В бюджет заложено 30 секунд.
Значит надо чтобы одна строка обрабатывалась за 0,009 милисекунд. А 10 000 строк должны обрабатываться за 90 милисекунд.
Значение 2400 мс будет первым пороговым значением для теста. Целевым значением будет 90 мс.

Таким образом feedback_loop выглядит так:

(0. один раз пишем тест, в котором замеряем время обработки тестового файла, и проверяем что он выполняется не более 2400 мс) 
1. профилируем программу. Определеям главную точку роста
2. Проделываем необходимую оптимизацию, для того чтобы оптимизировать главную точку роста
3. запускаем регрессионный тест. Если тест падает, вносим правки.
4. запускаем бенчмарк тест. Если тест падает, анализируем почему так произошло. Возможно используем профилирование для этого.
    Делаем соответствующие правки и возвращаемся к шагу 3.
    Если тест не падает, уменьшаем пороговое значение до 90 мс. Если тест успешен, то выходим из loop-а и переходим к финальному тесту.
    Если тест падает после установки в качестве нижнего порога целевого значения, то используем время, которое выводит тест при падении,
    и используем его как новое пороговое значение и возвращаемся к шагу 1.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался профилировщиком ruby-prof (а именно отчетами callstack и callgrind).

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- ruby prof callgrind показал, что главной точкой роста является Array::Select.
Эта операция выполняется 87% времени. Вызывается 1536 раз.
В алгоритме есть только один select: там где для каждого юзера выбираются сессии.
- решил использовать вместо вызова select метод group_by.
    Таким образом у нас получится hash, ключами которого будут user_id,
    а в качестве значений будут массивы сессии.
    Таким образом можно будет по идентификатору юзера можно будет быстро обращаться к массиву сессий.
- тест показал что алгоритм теперь выполняется за 400 мс.
- ruby prof callgrind показал что главной точкой роста теперь является команда Array::each,
    то есть главная точка роста изменилась.
    Считаем шаг успешным

### Ваша находка №2
- ruby prof callgrind показал что главной точкой роста теперь является команда Array::each.
    В тексте программы each используется в 4-х местах. По отчету не совсем понятно, какой из этих вызовов
    является главной точкой роста.
    В отчете ruby prof callstack уже видно, что это тот each, который вызывается непосредственно в главном методе work.
    И еще одним признаком является то, что внутри него вызывается метод all?
    Таким местом является расчет уникальных браузеров. Выделим его в отдельный метод, чтобы явно убедиться в том,
    что нужно оптимизировать именно это место.
    После такой реорганизации отчет callstack показал, что я был не прав.
    Новый метод uniq_browsers оказался на последнем месте из главных точек роста внутри метода work.
    На первом месте оказался Array::each внутри которого вызывается parse_session.
    Отчет callgrind показывает, что главной точкой роста является Array::each, который вызывается непосредственно в work.
    Под оба этих признака подходит each, который используется для обхода строк файла, и внутри парсятся сессии.
    Выделил это место в отдельный метод parse_lines.
    В этот раз callstack подтвердил, что главной точкой роста является парсинг юзеров и сессии (37% времени выполнения).
    Внутри которого вызывается parse_session почти 8400 раз. И метод split 20 000 раз.
    Callgrind подтвердил, что главной точкой роста является Array::each, коллером которого является новый метод parse_lines.
- Во-первых в глаза бросается, что метод split выполняется 20 000 раз, а строк всего 10 000.
    И действительно одна и та же строка файла, обрабатывается через split дважды.
    Вместо этого можно распарсить строку один раз и передать результат в методы, которые формируют соответствующие структуры.
- как изменилась метрика: прирост производительности был не замечен
- как изменился отчёт профилировщика: согласно callstack проблема сохранилась.
    Главной точкой роста по прежнему является метод parse_lines. Callgrind подтверждает это.

### Ваша находка №3
- какой отчёт показал главную точку роста: оба отчета callstack и callgrind показали,
    что главной точкой роста является метод parse_lines
- заменить метод each на метод while
- как изменилась метрика: удалось уменьшить пороговое значение на 20 мс (380 мс).
- как изменился отчёт профилировщика: оба отчета callstack и callgrind, показали что метод parse_lines остался главной точкой роста.

### Ваша находка №4
- какой отчёт показал главную точку роста: оба отчета callstack и callgrind показали,
      что главной точкой роста является метод parse_lines
- Убрал парсинг содержимого файла по символам переноса строки. Заменил вместо этого символы переноса строки на запятые.
    И сделал split(','). В итоге получился один большой массив. Который я передаю в новый метод parse_data.
    Внутри этого метода делается обход исходного массива в обычном цикле while, и в функции для формирования структур
    юзера и сессии передаются подмассивы необходимых размеров.
- как изменилась метрика: удалось уменьшить пороговое значение до 170 мс.
- как изменился отчёт профилировщика: callstack показал, что главная точка роста изменилась.
    Теперь это метод uniq_browsers (который был выделен на этапе 2). Callgrind показал, что главной точкой роста является
    метод all?, который как раз вызывается в методе uniq_browsers.

### Ваша находка №5
- какой отчёт показал главную точку роста: callstack показал, что главная точка роста
    это метод uniq_browsers (который был выделен на этапе 2).
    Callgrind показал, что главной точкой роста является метод all?, который вызывается в методе uniq_browsers.
- Расчет уникальных браузеров можно вынести выше, там где мы формируем структуры из сессий. А уникальности можно
    добиться за счет использования типа Set.
- как изменилась метрика: удалось уменьшить пороговое значение до 120 мс.
- как изменился отчёт профилировщика: callstack теперь показывает, что главной точкой роста является
    метод collect_stats_from_users. Callgrind показывает, что главная точка роста - Array::each.
    То есть точка роста изменилась.

### Ваша находка №6
- какой отчёт показал главную точку роста: callstack показывает, что главной точкой роста является
    метод collect_stats_from_users. Callgrind показывает, что главная точка роста - Array::each.
    Непонятно какой из вызовов collect_stats_from_users является главной точкой роста.
    Поэтому я сделал 7 копий этого метода, пронумеровал их, и в каждом месте вызвал уникальный метод
    со своим порядковым номером. В итоге оба отчета показали метод номер 7. 
    Это метод в котором происходит парсинг дат. Сallstack показал,   что он выполняется 37% времени.
    Callgrind подтвердил, что среди callers Array::each collect_stats_from_users7 на первом месте.
- Судя по исходным данным даты уже и так удовлетворяют формату. Поэтому я просто удалил парсинг даты,
    и форматирования в формат ISO.
- как изменилась метрика: удалось уменьшить пороговое значение до 90 мс.
- как изменился отчёт профилировщика: главные точки роста изменились. Теперь для callstack 
    это метод parse_data, в частности метод Set::add, который там содержится.
    Отчет callgrind показал главной точкой роста collect_stats_from_users4, в котором происходит
    вывод всех браузеров ползователя.
    
НАЧИНАЯ С ЭТОГО МОМЕНТА ПОНЯЛ, ЧТО РАСЧЕТ ЦЕЛЕВОГО ЗНАЧЕНИЯ ДЛЯ 10 000 СТРОК НЕВЕРНЫЙ.
ВЕДЬ ЗАВИСИМОСТЬ ОТ ОБЪЕМА ДАННЫХ НЕ ЛИНЕЙНАЯ, А СТЕПЕННАЯ. 
ПОЭТОМУ В ДАЛЬНЕЙШЕМ В СЛУЧАЕ УСПЕШНОЙ ОПТИМИЗАЦИИ ПО ОСНОВНОЙ МЕТРИКЕ ДОПОЛНИТЕЛЬНО
ЗАПУСКАЛ ТЕСТ ДЛЯ ИСХОДНОГО ФАЙЛА.
    
### Ваша находка №7
- какой отчёт показал главную точку роста: Теперь для callstack 
   это метод parse_data, в частности метод Set::add, который там содержится.
   Отчет callgrind показал главной точкой роста collect_stats_from_users4, в котором происходит
   вывод всех браузеров польхователя. То есть показания отчетов разошлись. Выберем главной точкой роста
   collect_stats_from_users4.
- Почти во всех вызовах collect_stats_from_users происходит повторное считывание сессии пользователей.
    Хотя данные можно подготовить один раз там, где мы собираем сессии для каждого юзера,
    и положить их в объект юзера.
- как изменилась метрика: удалось уменьшить пороговое значение до 75 мс
- как изменился отчёт профилировщика: точка роста изменилась

### Ваша находка №8
- точкой роста снова является Array::each. Но непонятно в каком месте. Выделил то место, где собираются
    сессии пользователя, и кладутся в объект User, в отдельный метод collect_stats.
    В итоге оба отчета показали, что collect_stats является главной точкой роста.
- В этом методе по сути снова происходит проход всех юзеров и всех сессии.
    Хотя это можно было сделать в самом начале, когда мы формировали структуры для юзеров и сессий.
    Там же собрал статистику в новые атрибуты юзера. Убрал формирование хешей юзеров и сессий,
    так как они не нужны для отчета, но GC наверное на них время потратит.
- как изменилась метрика: удалось уменьшить пороговое значение до 60 мс
- как изменился отчёт профилировщика: изменилась

### Ваша находка №9
- оба отчета (callstack и callgrind) показали, что главной точкой роста является метод parse_data.
    В нем основной точкой роста является метод Set::add
- заменил на Set на Hash
- как изменилась метрика: практически не изменилась
- как изменился отчёт профилировщика: изменился, Set::add ушел из отчета

### Ваша находка №10
- оба отчета (callstack и callgrind) показали, что главной точкой роста является Сlass.new
    в методе parse_data
- заменил класс на хеш
- как изменилась метрика: уменьшил до 57 мс
- как изменился отчёт профилировщика: Сlass.new ушел из отчетов

### Ваша находка №11
- оба отчета (callstack и callgrind) показали, что основной точкой роста
    является метод upcase, который вызывается в parse_data.
- вместо того чтобы приводить каждый браузер к upcase, делаю это уже на сформированных строках (после join)
- как изменилась метрика: практически не изменилась
- как изменился отчёт профилировщика: изменился

### Ваша находка №12
- оба отчета (callstack и callgrind) показали, что основной точкой роста
    являются методы to_i, include?, sort, которые вызываются в методе parse_data
- include? заменил на start_with?, to_i оставил, sort.reverse заменил на sort!.reverse! без присваивания
- как изменилась метрика: практически не изменилась
- как изменился отчёт профилировщика: по прежнему parse_data главная точка роста,
    оптимизированные методы заменились новыми
    
### Ваша находка №13
- хоть parse_data и приходится первым в списке профилировщиков, этот метод уже не поддается оптимизации.
    Поэтому перейдем к следующей точке роста.
    Согласно callgrind это Array::each, коллерами которого являются методы collect_stats_from_usersN.
- В нем самое долгое время отрабатывает метод merge, от которого можно избавиться в пользу обычного присваивания.
    Заодно уберем конкатенацию строк через оператор + в методе collect_stats_from_users.
- как изменилась метрика: уменьшил до 48 мс
- как изменился отчёт профилировщика: первым в отчете по прежнему является parse_data, на втором Array::each

### Ваша находка №14
- первым в отчете по прежнему является parse_data, на втором Array::each
- Всё таки придумал как оптимизировать parse_data. Одним из его callee является часто вызываемый upcase.
    Я подумал, что если сделать сразу upcase всего содержимого файла, а потом capitalize имени и фамилии юзеров,
    ведь их намного меньше чем браузеров.
- как изменилась метрика: уменьшил до 46 мс. Исходный файл обрабатывается за 30 секунд!
- как изменился отчёт профилировщика: upcase исчез из списка callees
    
## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы для тестового кейса с 2400 мс до 46 мс и уложиться в заданный бюджет.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы был написан тест.
В тесте используется библиотека rspec-benchmark. В тесте устанавливается нижнее пороговое значение в милисекундах - время за которое должен выполниться алгоритм.
Тест использует заранее подготовленный файл, содержащий первые 10000 строк исходного файла.
Кроме того в тесте используются параметры warmup, и sample.
Это делается для того чтобы во-первых избежать прыгающих значений теста,
во-вторых чтобы увидеть в результате диапазон значений, которые наблюдались в результате выполнения сэмплов.
Так можно увидеть худшее значение и выставить его в качестве нового порогового значение для дальнейших оптимизации.
Тест расположен по пути spec/report/report_spec.rb
