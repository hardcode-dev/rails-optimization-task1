# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я сформировал 3 файла(на 1536, 3072 и 6144 строк) на которых мы будем замерять производительность. 
Бенчмарк перед оптимизацией показал - что при увеличение данных в 2 раза - скорость обработки увеличивается чуть более чем в 3 раза:

    1536-rows:  0.058431
    3072-rows:  0.192021
    6144-rows:  0.665419


## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, 
который позволил мне получать обратную связь по эффективности сделанных изменений за 25секунд

Вот как я построил `feedback_loop`: 
- Тестирование работоспособности программы: самое важное - чтоб все работало правильно
- Тестирование метрик - Для защиты от потери достигнутого прогресса
- Бенчмарк
- Профилирование ruby prof


## Вникаем в детали системы, чтобы найти главные точки роста
Перед началом оптимизации - я решил отрефракторить код, разбив основные этапы программы на именованные методы, для более удобной работы в будущем.
 
Для того, чтобы найти "точки роста" для оптимизации я воспользовался профилирование RubyProf

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- По отчету RubyProf - Graph основная точка роста - это Array#select
- Решил глобально поменять загрузку данных. Логичней будет данные сессией пользователя загрузить сразу в объект к пользователю. 
А потом уже с этого объекта получать нужную нам информацию - это сразу сократит множества переборов.
- метрика изменилась на 6144-rows: с 0.665419 до 0.067954 прирост примерно 1000%
- отчёт профилировщика изменился глобально. Текущая точка роста уже отсутствовала - по причине большого рефракторинга. Код стал намного чище

### Ваша находка №2
- По отчету RubyProf - CallStack основная точка роста - это Date.parse
- Внимательно просмотрев входные/выходные данные - пришел к выводу, что парсинг дат нам не нужен. Мы и так получаем ее в нужном формате. убираем парсинг/конвертацию
- метрика на 6144-rows: с 0.067954 до 0.041583 прирост примерно на 38%
- проблема была решена

### Ваша находка №3
- stackprof показал - что точка роста у нас на сборе уникальных браузеров при загрузке данных. Мы каждый раз проверяем - есть ли такой браузер в массиве и если нет, добавляем в него новый элемент.
- будем добавлять все в массив, а потом сделаем uniq!
- метрика на 6144-rows: с 0.041583 до 0.032738 прирост примерно на 22%
- проблема была решена. Тестим основной файл - Ура! залезаем в 25секунд. 

### Завершающий этап
- Добавил прогрессбар. Время работы увеличилось до 27с. Отлично! укладываемся в метрику. 
- Тест на линейность работает через раз. Для начала увеличим количество данных в файлах - для большой точности. Тест падает все так же через раз. Профилируем дальше на новом объеме данных
Следующая точка роста - split файла на строки. Попытаемся прочесть файл по-другому.
поменял файл `File.read(@file_path).split("\n")` на `IO.readlines(@file_path)` чтение файла ускорилось в 4раза! 
Также избавимся от `parse_session` и `parse_user` так как эти хеши мы практически не используем, а на них уходит 9% времени 
Дошли уже до 21 секунд в бенчмарке и 24 с прогресбаром в обычной работе. Но на линейность так и не вышел (  

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 0.665419 до 0.032738 и уложиться в заданный бюджет с приличным запасом.
Но пришлось, к сожалению, многое переписать - от исходной задачи мало что осталось. На этой задаче научился пользоваться профилировщиками и искать слабые места в коде

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы я написал перформ тест с небольшим запасом - проверки на 40т строк.

