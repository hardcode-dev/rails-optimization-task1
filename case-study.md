# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: время обработки программой файла размером 40000 строк.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 20 секунд.

Вот как я построил `feedback_loop`: т.к. тест проверяющий корректность работы программы уже имелся, мне оставалось добавить вывод метрики, чтобы понимать стала программа работать быстрее или нет.

В итоге имеем шаги:
1. Профилируем программу
2. Модифицируем программу в главной точке роста
3. Прогоняем тесты и выплевываем результат метрики: `ruby task-1.rb`
4. Если производительность увеличилась, то коммит. Если нет, то реверт.

Повторять до тех пор пока метрика не уложится в бюджет.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался профилировщиками rbspy, ruby-prof и StackProf.

Вот какие проблемы удалось найти и решить

### Находка №1 - Не эффективное получение сессий пользователя
- увидел в flat отчете ruby-prof-а
- для ускорения работы я решил сформировать на этапе парсинга файла хэш с ключом по ИД пользователя который будет хранить все сессии конкретного пользователя
- время выполнения снизилось c 22.8 до 1.05 секунд
- в отчёте профилировщика исправленная проблема перестала быть главной точкой роста

### Находка №2 - Не эффективное добавление элемента в массив
- наглядно видно в отчете StackProf CLI
- формировать массив путем вставки нового элемента в уже имеющийся массив
- время выполнения снизилось c 1.05 до 0.7 секунд
- в отчёте профилировщика исправленная проблема перестала быть главной точкой роста

### Находка №3 - Не эффективный подсчёт количества уникальных браузеров
- видно в callstack отчете ruby-prof-а
- можно использовать хэш у которого в качестве ключей будут названия браузеров
- время выполнения снизилось c 0.7 до 0.53 секунд
- в отчёте профилировщика исправленная проблема перестала быть главной точкой роста

### Находка №3 - Множество вызовов метода collect_stats_from_users
- видно в callstack отчете ruby-prof-а
- вместо множества вызовов метода `collect_stats_from_users` можно вызвать его один раз и передать хэш со всеми необходимыми ключами
- время выполнения снизилось c 0.53 до 0.48 секунд
- в отчёте профилировщика исправленная проблема перестала быть главной точкой роста

### Находка №4 - Не эффективное добавление элемента в массив
- наглядно видно в отчете StackProf CLI
- формировать массив путем вставки нового элемента в уже имеющийся массив
- время выполнения снизилось c 0.48 до 0.39 секунд
- в отчёте профилировщика исправленная проблема перестала быть главной точкой роста

### Находка №5 - Не эффективное формирование дат сессий через запятую в обратном порядке в формате iso8601
- видно в callstack отчете ruby-prof-а
- убрать все лишние шаги
- время выполнения снизилось c 0.39 до 0.25 секунд
- в отчёте профилировщика исправленная проблема перестала быть главной точкой роста

### Находка №5 - Лишнее разбиение строки при парсинге файла
- видно в callstack отчете ruby-prof-а
- использовать уже имеющуюся переменную со столбцами из файла
- время выполнения снизилось c 0.25 до 0.21 секунд
- в отчёте профилировщика исправленная проблема перестала быть главной точкой роста

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы c 22.8 до 0.21 секунды при обработке файла на 40000 строк и уложиться в заданный бюджет.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы я написал performance-тест который проверяет время выполнения.
