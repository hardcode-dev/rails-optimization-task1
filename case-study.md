# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: Время выполнения программы на данных в ~300к записей ~30 секунд

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *1 секунда*

Вот как я построил `feedback_loop`: *как вы построили feedback_loop* решил разделить запуск тестов и запуск проверки производительности в разных файлах, а разграничивать передачу файла через передачу аргумента. От автоматического запуска теста при сахраненнии отказался, т.к автоматический трекинг изменений и запуск тестов немного раздражает.

В итоге получилось:
* profile
* modify
* tests
* benchmark
* commit если все хорошо

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался *инструментом ruby-prof в силу его минималистичности и простоты генерации отчетов*

### Перед оптимизацией снял замеры на тестовом датасете в 10к записей

```
Measure Mode: wall_time
Thread ID: 260
Fiber ID: 240
Total: 7.621647
Sort by: self_time

 %self      total      self      wait     child     calls  name                           location
 89.42      6.815     6.815     0.000     0.000     2288   Array#select
  5.54      7.602     0.422     0.000     7.180       10   Array#each
  2.23      0.171     0.170     0.000     0.001    15000   Array#all?
  0.56      0.129     0.043     0.000     0.086    25170   Array#map
  0.44      0.072     0.034     0.000     0.038    12712   <Class::Date>#parse
```

### Гипотеза №1:
Воспользовался отчетом от ruby-prof в формате flat. Изучив полученынй отчет стало понятно что cудя по всему метод select очень часто вызывается. Решил посмотреть что с ним может быть не так, и подумал что формирование сессий можно агрегировать на моменте первого прохода, чтоб не делать двойную работу.

После оптимизации получилась следующая картина

```
Measure Mode: wall_time
Thread ID: 260
Fiber ID: 240
Total: 0.455129
Sort by: self_time

 %self      total      self      wait     child     calls  name                           location
 36.74      0.168     0.167     0.000     0.001    15000   Array#all?
 15.16      0.437     0.069     0.000     0.368       10   Array#each
  9.86      0.131     0.045     0.000     0.086    25170   Array#map
  7.33      0.072     0.033     0.000     0.039    12712   <Class::Date>#parse
  5.49      0.025     0.025     0.000     0.000    30001   String#split
  3.65      0.017     0.017     0.000     0.000    25424   Regexp#match
```

На тестовых данных: было Total: 7.621647 стало Total: 0.455129. Профит от такого подхода очевиден

На исходных данных в 300к записей: Раньше не понятно когда завершится, сейчас уложились в 2 минуты.

### Гипотеза  №2
Вторая точка роста, избавится от излишних переборов всех брайзеров для поиска уникального набора.

```
 36.74      0.168     0.167     0.000     0.001    15000   Array#all?
```

По логике программы, решил просто заменить массив на Set т.к он реализова поверх хеша с встроенной возможности определения уникальности и o(1) сложность

```
Measure Mode: wall_time
Thread ID: 260
Fiber ID: 240
Total: 0.289249
Sort by: self_time

 %self      total      self      wait     child     calls  name                           location
 23.27      0.271     0.067     0.000     0.203       10   Array#each
 15.21      0.125     0.044     0.000     0.081    25170   Array#map
 10.55      0.068     0.031     0.000     0.037    12712   <Class::Date>#parse
  9.04      0.026     0.026     0.000     0.000    30001   String#split
  5.57      0.016     0.016     0.000     0.000    25424   Regexp#match
```

В итоге получили еще прирост в полтора раза с Total: 0.455129 до Total: 0.289249

### Гипотеза №3
По предыдущему отчету выглядит так что у нас вызывается очень часто `.map`, и проблема вовсе не в `.each` методе а то что внутри мы очень много раз запускаем `.map`

Заметил что там метод сббора статистики запускает перебор всех юзеров на каждый его вызов, и решил развернуть его в обратную сторону и унести сбор отчета в метод work без всяких блоков, а найминг оставить в виде переменных

```
Measure Mode: wall_time
Thread ID: 260
Fiber ID: 240
Total: 0.260743
Sort by: self_time

 %self      total      self      wait     child     calls  name                           location
 21.48      0.242     0.056     0.000     0.185        4   Array#each
 11.78      0.067     0.031     0.000     0.037    12712   <Class::Date>#parse
 10.46      0.106     0.027     0.000     0.079    16018   Array#map
  9.73      0.025     0.025     0.000     0.000    30001   String#split
  5.94      0.015     0.015     0.000     0.000    25424   Regexp#match
```

Помогло не особо судя по метрикам времени, но зато количество вызовов .map и .each сократилось в разы, что даст прирост в производительности на большем наборе данных.

### Гипотеза №4

Решил увеличить семпл для сбора статисики, для более наглядного отчета, но даже из предыдущего видно что парсинг даты занимает огромное количество процессерного времени. Изучив исходники понял, что можно сначала приводить даты к определенному формату `'%Y-%m-%d'` а только потом уже сортировать по iso8601. Есть другая мысль о том чтоб лишний раз не парсить данные, а агрегировать их в хеше, но вернусь к ней если еще раз упрусь в производительность Парсинга даты.

Новый набор семпла с большим набором тестовых данных

```
Measure Mode: wall_time
Thread ID: 260
Fiber ID: 240
Total: 2.003549
Sort by: self_time

 %self      total      self      wait     child     calls  name                           location
 21.98      1.866     0.440     0.000     1.425        4   Array#each
 11.69      0.506     0.234     0.000     0.272    84569   <Class::Date>#parse
 10.68      0.214     0.214     0.000     0.000   200001   String#split
 10.27      0.801     0.206     0.000     0.595   108019   Array#map
  6.03      0.121     0.121     0.000     0.000   169138   Regexp#match
```

После оптимизации

```
Measure Mode: wall_time
Thread ID: 260
Fiber ID: 240
Total: 1.797544
Sort by: self_time

 %self      total      self      wait     child     calls  name                           location
 24.89      1.557     0.447     0.000     1.110        4   Array#each
 13.68      0.246     0.246     0.000     0.000   200001   String#split
  9.64      0.454     0.173     0.000     0.281    92588   Array#map
  6.67      0.236     0.120     0.000     0.116    84569   <Class::Date>#strptime
  5.81      0.105     0.105     0.000     0.000    84569   Regexp#match
```

Парсинг больше не является точкой роста, результат достигнут.

### Гипотеза №5

Смущает количество вызовов метода `.split`, первый попвшийся split это чтение файла File.read(file).split("\n").
Решино избавится от .split в методах парсинга, и оставить только на первом уровне.

```
Measure Mode: wall_time
Thread ID: 260
Fiber ID: 240
Total: 1.548172
Sort by: self_time

 %self      total      self      wait     child     calls  name                           location
 25.07      1.291     0.388     0.000     0.903        4   Array#each
 11.78      0.465     0.182     0.000     0.283    92588   Array#map
  7.80      0.236     0.121     0.000     0.115    84569   <Class::Date>#iso8601
  6.74      0.104     0.104     0.000     0.000    84569   Regexp#match
  6.61      0.102     0.102     0.000     0.000   100001   String#split
  4.02      0.086     0.062     0.000     0.024    30863   Array#sort
```

Стало лучше, но не так уж и значитально

### Гипотеза №6

Все еще очень много переборов `.map`

* Убрать `.map(&:to_i)` и оставил каст типов в самом первом переборе, все же лишний раз не переберать один и тот же набор данных.
* Объеденить `.map` с перебором сессий которые происходят аж 3 раза, в один общий хеш.

```
Measure Mode: wall_time
Thread ID: 260
Fiber ID: 240
Total: 1.348294
Sort by: self_time

 %self      total      self      wait     child     calls  name                           location
 30.86      1.083     0.416     0.000     0.666    15434  *Array#each
  8.99      0.242     0.121     0.000     0.121    84569   <Class::Date>#iso8601
  8.09      0.109     0.109     0.000     0.000    84569   Regexp#match
  7.24      0.098     0.098     0.000     0.000   100001   String#split
  3.89      0.085     0.052     0.000     0.032    15432   Array#map
```

Не особо помогло, все в рамках погрешности (~2 сек). Но зато после оптимизации появилась новая точка роста.

### Гипотеза №7

Сократить количество `.each`

Надо пересмотреть подход к формированию хеша. Выделить структуру где будут User инстансы с готовыми сессиями.

```
Measure Mode: wall_time
Thread ID: 260
Fiber ID: 240
Total: 1.357117
Sort by: self_time

 %self      total      self      wait     child     calls  name                           location
 37.18      1.136     0.505     0.000     0.632    15434  *Array#each
  9.12      0.124     0.124     0.000     0.000   100001   String#split
  8.04      0.123     0.109     0.000     0.013    84569   <Class::Date>#strptime
  4.91      0.104     0.067     0.000     0.037    15433   Array#map
```

  Вроде как нет прогрсса, но при этом на болшой выборке получилось уже 50 секунд вместо 2 минут, что уже очень близко к нашей метрике.

```
Measure Mode: wall_time
Thread ID: 260
Fiber ID: 240
Total: 52.672522
Sort by: self_time

 %self      total      self      wait     child     calls  name                           location
 33.00     39.211    17.380     0.000    21.830   500003  *Array#each
 11.47      6.044     6.043     0.000     0.001        1   JSON::Ext::Generator::GeneratorMethods::Hash#to_json
  8.70      4.580     4.580     0.000     0.000  3250941   String#split
  6.92      4.078     3.643     0.000     0.435  2750940   <Class::Date>#strptime
  3.93      3.540     2.068     0.000     1.472   500002   Array#map
  3.92      2.062     2.062     0.000     0.000  7577617   String#upcase
```

### Гипотеза №8

Решил сразу составить список в рамках одного отчета того что надо оптимизировать, т.к по отдельности это уже не будет нести ощутимый эффект, но скопом можно сравнить на сколько сильно это повлияет.

Судя по отчету все еще много .each надо дальше убирать количество переборов, и очень много вызовов .split, все остальное пока кажется незначитальным

Что стоит оптимизировать чтоб избавится от большого количества .each вызовов

* выделить одну общую структуру пользователей сразу с сессиями
* заменить read со сплитом на readlines а удаление .(\n) делать через специальный метод `.chomp` там где это необходимо
* добавить guard для юзера/сессий и добавить
*  `.start_with?` для скорости сравнения
* избавится от перебора сессий, а подсчет сессий вынести в инкрементную переменную
* избавится от перебора браузеров
* убрать лишние .map в AllBrowsers и заиспользовать unique_browser_set
* Организовать набор дат внутри хеша, чтоб ыкаждый раз не парсить а брать по ключу если такая дата уже существует
* Заменить медленное сравнение ~= на .match?
* избавится от огромного вызовы .upcase в коде выделив в общую переменную

В итоге удалось сократить до 30 секунд (скачет от 28 до 33), 5 секунды в рамках погрешности систем. Разницы что с GC что без так же в рамках погрешности.

```
Measure Mode: wall_time
Thread ID: 260
Fiber ID: 240
Total: 28.689886
Sort by: self_time

 %self      total      self      wait     child     calls  name                           location
 33.07     20.307     9.488     0.000    10.819   500001   Array#each
 11.78      3.380     3.380     0.000     0.000  3250940   String#split
 10.40     14.176     2.984     0.000    11.193        3   Hash#each_key
  6.10      1.751     1.751     0.000     0.000  2750940   Object#parse_session
  5.17      1.484     1.484     0.000     0.000  2750940   Date#iso8601

```

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*
