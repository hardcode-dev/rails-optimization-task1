Время выполнения на 5000: 0.210786
Время выполнения на 10000: 0.726360
Время выполнения на 20000: 2.843040
Время выполнения на 40000: 12.927038

рост квадратичный -> O(n^2)
f(x) ~ 8*10^-9 * x^2
время выполнения на 3250940: ~23,5 часа

1) Начнем с объема 20000 (около 3сек), напишем тест на перфманс (не больше 3 секунд)
2) используем профилировщик rbspy
3) по call tree видим, что больше всего времени уходит на блок users.each в методе work (83,8%), а в нем на блок select (58,8%) (user_sessions = sessions.select { |session| session['user_id'] == user['id'] })
4) заменим метод select на предварительную группировку по пользователям. теперь блок users.each занимает 2% времени
5) проверим время на 20000: 0.350901
5) заменим each + [] << на map. профилировщик с дефолтным значением samples per sec (97) не показал блок в статистике, поменяла на 1000 samples per sec - не показал блок в статистике
5) проверим время на 20000: 0.350526 (не изменилось)
6) поправим тест на перфманс (поставим границу 0.4 с)

1) проверим время на 40000: 1.077637, мало
2) проверим 80000: 4.540294
3) напишем перфоманс тест на 80000 (не больше 4.6 сек)
4) воспользуемся профилировщиком ruby prof flat отчет
5) по отчету видно что больше всего времени занимает конкатенация массивов:
   %self      total      self      wait     child     calls  name                           location
   30.44      2.073     2.073     0.000     0.000    80200   Array#+
6) в коде конкатенация используемся при сборке users = [], sessions = [], uniqueBrowsers = []
7) uniqueBrowsers заменила на map + uniq, users / sessions на append:
   0.62      0.007     0.007     0.000     0.000    80000   Array#append
8) время на 80000: 0.571369
9) поправим тест на перфманс (поставим границу 0.6 с)

1) проверим время на 160000: 1.162673, мало
2) проверим время на 320000: 2.476740, мало
3) заметим что сложность стала больше похожа на линейную, чем на квадратичную
3) проверим время на 640000: 5.804469
4) напишем перфоманс тест на 640000 (не больше 6 сек)
5) воспользуемся профилировщиком stackprof
   TOTAL    (pct)     SAMPLES    (pct)     FRAME
   1304  (23.5%)        1304  (23.5%)     (marking)
   2634  (47.5%)         705  (12.7%)     Object#collect_stats_from_users
что такое (marking) не понятно, но видно что больше всего времени уходит на collect_stats_from_users
   callers:
   2634  (  100.0%)  Object#work
   2617  (   99.4%)  Array#each
   callees (1929 total):
   2634  (  136.5%)  Array#each
   1798  (   93.2%)  Object#work
   114  (    5.9%)  Hash#merge

6) из кода видно, что метод вызывается 7 раз с разными блоками, каждый раз перебирая заново всех юзеров
7) заметим что в методе используется не оптимальная конкатенация строк, заменим + на "#{...}" -> 5.212167 c
8) заменим 7 вызовов метода на один вызов с готовым хэшом:
   TOTAL    (pct)     SAMPLES    (pct)     FRAME
   1938  (40.8%)         122   (2.6%)     Object#collect_stats_from_users
9) поправим заполнение хэша и его мердж: отдельно преобразуем время и браузеры в переменную и будем их использовть для дальнейшего заполнения
было: 1716  (36.1%)         245   (5.2%)     Array#map
стало:  1534  (34.1%)         151   (3.4%)     Array#map
немного но честная работа
10) проверим время на 640000: 4.317787, не сильный прирост
11) поправим тест на перфманс (поставим границу 4.5 с)

1) продолжим использовать 640000
2) в топе самых долгих методов остается collect_stats_from_users (42%), посмотрим внутрь - там метод Date.parse (total 25%)
3) заметим, что даты приходят в iso8601, поэтому можно опустить парсинг и сразу использовать
4) то снизили затрачиваемое время в collect_stats_from_users до 19%
5) проверим время на 640000: ~3
6) поправим тест на перфманс (поставим границу 3.1 с)

1) продолжим использовать 640000
2) в топе методов Array#each (52%), из них 59% вызывается из метода work, в нем 35% - collect_stats_from_users, 22% - parse_session, в нем string split
совокупно string split занимает 14%, уберем лишние вызовы
3) теперь string split занимает 11%
4) Array#each все еще в топе, теперь в нем основное время занимает метод collect_stats_from_users
5) рассмотрим его внимательнее:
перебирается массив user_object, для каждого юзера собирается статистика по его сессиям
можно попробовать внести преобразование типов в методы парсинга 2.228482
заменим count на length 2.166889
6) поправим тест на перфманс (поставим границу 2.5 с)
7) проверим время на 1млн: 3.760000
8) проверим на полном файле: 17.444283
9) 

