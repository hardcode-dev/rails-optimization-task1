# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: 
*Скорость обработки файла*

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 10-15 секунд

Вот как я построил `feedback_loop`:

Так как измерить скороть обработки файла data_large.txt скриптом без оптимизации выглядит слишком большим, было принято решение подготовить несколько
наборов тестовых данных размером в 0.5mb, 1mb, 5mb, 25mb, 60mb и использовать их последовательно, переходя к большему объему тестового файла,
если скрипт обрабатывал объем менее чем за 10 секнунд.

Подготовим файлы подходящего объема
- wc data_large.txt - в файле 3кк строк (134 mb) ~ 30к строк на mb
- head -15000 data_large.txt > data05mb.txt
- head -30000 data_large.txt > data1mb.txt
- head -150000 data_large.txt > data5mb.txt 
- head -750000 data_large.txt > data25mb.txt
- head -1800000 data_large.txt > data60mb.txt

Далее модифицируем скрипт таким образом, чтобы можно было удобно вызывать его, передавая название обрабатываемого файла и выводя время обработки файла.
Каждый раз, запуская обработку файла, запускаем тест и убеждаемся, что программа работает корректно, выводим время обработки файла.

## Вникаем в детали системы, чтобы найти главные точки роста
Попробуем отключить GC, посмотрим, на сколько это повлияет на скорость обработки файла 0.5mb
- запускаем ruby task-1.rb data05mb.txt... processed data05mb.txt in 12.421244000001025 sec
- устанавливаем GC.disable
- запускаем ruby task-1.rb data05mb.txt... processed data05mb.txt in 11.271920999999566 sec
Есть некоторый прирост, но он составляет всего 10-15%. Судя по всему на данном этапе проблемой является вычислительная сложность алгоритма, 
а не потребление памяти. Попробуем найти самые горячие точки и "точки роста". 

### rbspy
Для начала я попробовал исследовать программу при помощи профилировщика rbspy
- sudo rbspy record --pid 55384 

Отчет rbspy не дал какой-то конкретной информации, однако строчка 

- 12.79   100.00  c function - unknown

Может говорить, что большая часть работы производится некой внешней С библиотекой. Продолжим исследование

### ruby-prof
Попробуем исследовать программу при помощи профилировщика ruby-prof в разных режимах

- gem install ruby-prof
- require 'ruby-prof'

### ruby-prof flat - Array#select
Во flat отчете ruby-prof видно, что максимум времени выполнения скрипта занимает функция Array#select
- %self      total      self      wait     child     calls  name                           location
- 89.11     11.330    11.330     0.000     0.000     2288   Array#select

Метод select используется в единственном месте программы, строка 105.
В данный момент это самая горячая точка программы, попробуем ее оптимизировать.
Исходное значение метрики оптимизации - 12 секунд (файл 0.5mb), пробуем внести изменения в код.

Попробуем полностью избавиться от метода select, а парсинг сессий пользователей провести прямо в методе file_lines.each
при первоначальном чтении файла, сразу сохраняя сессиии в user_sessions_hash. 

Время разбора файла размером 0.5mb сократилось до 2-x секунд. Коммитим изменения.

### Оценка результатов первой оптимизации
Так как парсинг файла data1mb.txt занимает всего 3 секунды, сразу переходим к data5mb.txt
Оценим текущее состояние метрики
- process data5mb.txt ...
- ... processed data5mb.txt in 47.406245999998646 sec

Результат в 47 секунд оставляет желать лучшего. Так же становится ясно, что время работы скрипта увеличивется 
значительно быстрее увеличения размера файла.

Попробуем отключить GC, чтобы оценить его внияние на работу скрипта на объеме данных в 5mb.

Дождаться выполнения скрипта не удалось, похоже что скрипт потребляет всю доступную память и своп, после чего все зависает.

Попробуем вернуться к профилированию через ruby-prof.

### ruby-prof Array#each
Запустив ruby-prof во flat режиме еще раз, можно увидеть новый топ метод по времени работы - Array#each
- %self      total      self      wait     child     calls  name                           location
- 85.17     46.393    39.992     0.000     6.401       10   Array#each
- 5.02      2.372     2.357     0.000     0.015   150000   Array#all?

Array#each вызывается в нескольких местах программы. Попробуем сформировать отчет ruby-prof в GraphHtml.
Подозрение падает на Array#each вызванный из Object#work, это место выглядит явно не оптимальным,
так как тут происходит чтение полного файла в память. Однако, рефакторинг с построчнми чтением файла не дает прироста
производительности.

Rbspy все так же показывает в топе c function - unknown. Выжать что-то большее из GraphHtml и flat не удается

Пока откатываю все изменения обратно, решаю попробовать ruby-prof в режиме CallStack

Так как файл размером 5mb обрабатывается достаточно долго, решил добавить промежуточный объем 3mb
- head -90000 data_large.txt > data3mb.txt

Из отчета CallStack стало понятно, что ruby-prof не может разделить вызовы Array#each внутри Object#work, 
поэтому я решил провести рефакторинг и разнести вызовы each в отдельные методы.

Значение метрики оптимизации - 10 секунд (файл 3mb)

Я выделил два новых метода, parse_file и process_line, переписал чтение файла на построчный режим. 
Это улучшило метрику всего на 1 секунду, то-есть основная проблема производительности не была 
в данном моменте связана с чтением файла. Тем не менее, метрика улучшилась, зафиксируем результат  

#String#split
В этом месте я обратил внимание на следующие строки в отчете ruby-prof CallStack:
- 76.83% (100.00%) <Class::IO>#foreach [1 calls, 1 total]
- 2.38% (3.10%) Object#process_line [90000 calls, 90000 total]
- 1.90% (79.64%) String#split [90000 calls, 180000 total]

Тут можно заметить, что Object#process_line вызывается 90000 раз - это сответствует количеству строк в файле размером 3mb
А String#split вызывается 180000 total - в три раза больше. Возможно, split реализована низкоуровнево, и это именно она та 
самая c function - unknown в отчете rbspy. 

Попробуем найти все вызовы split и изменить код таким образом, чтобы вызывать ее не более 1 раза для каждой строки файла с данными.

Значение метрики оптимизации - 16 секунд (файл 3mb), внесем изменения в код

После переписывания кода количество вызовов split сократилось до количества строк в файле, однако значение метрики почти не изменилось.
Принимаю решение коммитить изменения, так как метрика не стала хуже, а код стал более понятным и читаемым

#Оценка результатов воторй оптимизации

После второго раунда оптимизации значение метрики практически не улучшилось. Кроме того, отчет ruby-prof CallStack
выглядел очень странно 
- 75.51% (100.00%) <Class::IO>#foreach [1 calls, 1 total]
- > 1.70% (2.25%) Object#process_line [90000 calls, 90000 total]
- >> 1.19% (69.97%) String#split [90000 calls, 180000 total]
- > 1.57% (2.07%) Object#parse_session [76100 calls, 76100 total]

Метод <Class::IO>#foreach потребляет 75% процессорного времени, однако оба вызванных им методоа потребляют всего 1,5-2%.
В сумме с беспрецедентным жором памяти скриптом при отключенном GC, я сделал предположение, что остальное время тратится 
как раз на сборку мусора. Возможно, как раз работу GC rbspy показывал как c function - unknown

# users = users + [user]
После выделения чтения файла в отдельный метод, понятно, что искать проблему с потреблением памяти надо именно в нем.
В строках 64 и 69 мы видим констркции вида users = users + [user] и sessions = sessions + [session]. Оптимизируем этот код,
чтобы не создавать слишком много объектов.

Значение метрики оптимизации - 19 секунд (файл 3mb)
После внесения изменений в код с использованием оператора << значение метрики упало до 5-и секунд. Коммитим.

# Date.parse
Продолжим изумение скрипта. В отчете ruby-prof CallStack обнаруживается метод Date#parse, занимающий значительную часть
процессорного времени. Данный метод вызывается в скрипте один раз, в строке 160. Из лекции мы знаем, что Date#parse очень медленный метод. 
Посмотрим, можем ли мы привести даты к формату iso8601 менее затратным способом

- 100.00% (100.00%) Object#work [1 calls, 1 total]
- > 47.07% (47.07%) Array#each [2 calls, 9 total]
- >> 26.81% (56.96%) Array#map [253671 calls, 253673 total]
- >>> 18.92% (70.57%) <Class::Date>#parse [126939 calls, 126939 total]

Так как файл размером 3 мегабайта обрабатывается слишком быстро, переходим к использованию файла размером 5mb.
Значение метрики оптимизации - 9.9 секунд (файл 5mb). Попробуем внести изменения в код.

При ближайшем рассмотрении кажется, что даты в файле уже в формате iso8601, и можно их вообще не конвертировать. 
Метрика уменьшается до 7 секунд, коммитим.

# Array#all?
Пока не удается перейти к обработке файла размером 25mb, так как она занимает более 60-и секунд,
остаемся на файле размером 5mb. В отчете ruby-prof CallStack видим следующее:

- 100.00% (100.00%) Object#work [1 calls, 1 total]
- > 61.89% (61.89%) Array#each [2 calls, 9 total]
- >> 28.68% (46.35%) Array#all? [150000 calls, 150000 total]

Метод Array#all? вызывается в программе в двух местах, нас интересует вызов all? внутри each - а это происходит только
в строке 101. В этом месте обсчитывается количество уникальных браузеров, попробуем перенести эту логику на этап
построчного чтения файла

Значение метрики оптимизации - 7 секунд (файл 5mb), попробуем внести изменения в код.
После оптимизации метрика уменьшается до 5 секунд, коммитим

# Array#map

Снова смотрим в отчет ruby-prof.
Топ метод по времени работы - это Array#each, внутри которого вызываются  Array#map

- 100.00% (100.00%) Object#work [1 calls, 1 total]
- > 68.57% (68.57%) Array#each [1 calls, 8 total]
- >> 4.57% (6.66%) Array#map [922176 calls, 922178 total]
- >>> 1.08% (1.57%) Hash#merge [806904 calls, 806904 total]

Я обратил внимание на количество вызовов метода map, число очень большое, при этом из лекции мы знаем, что map очень 
затратный в плане производительности метод. Осматривая код скрипта, я обнаружил несколько мест, где map вызывается
последовательно в стиле 
- { 'totalTime' => user.sessions.map {|s| s['time']}.map {|t| t.to_i}.sum.to_s + ' min.' }
Попробуем оптимизировать скрипт, сократив количество вызовов map, объеденив блоки в один.

Значение метрики оптимизации - 5 секунд (файл 5mb), попробуем внести изменения в код.
Количество вызовов map, упало, но целевая метрика уменьшилась всего на 0,5 секунды.
Тем не менее, улучшение есть и код стал более читаемым. Коммитим.

# Array#each
В топ вызываемых методов выходит Array#each, этот метод вызывается в нескольких местах. Выдвигаю предположение, 
что значительную нагрузку создает вызов each c блоком создания объектов 
- User.new(attributes: attributes, sessions: user_sessions)
Для подтверждения теории, выношу создание Users в отдельный метод create_users_objects. Этот метод сразу выходит в 
топ отчета и вызов Array#each в нем так же создает значительную нагрузку.

- 100.00% (100.00%) Object#work [1 calls, 1 total]
- > 44.92% (44.92%) Object#create_users_objects [1 calls, 1 total]
- >> 44.92% (100.00%) Array#each [1 calls, 8 total]

Попробуем оптимизировать данный код, значение метрики оптимизации - 4 секунды (файл 5mb)
В отчете, внутри методов Array#each нет методов, потребляющих заничельное количество ресурсов. Выше уже был похожий момент,
означавший трату ресурсов на работу GC. Изменив потребляющий значительное количество памяти код на 
- users_objects << user_object
удалось уменьшить значение метрики до 3-х секунд. Коммитим

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.


*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*
