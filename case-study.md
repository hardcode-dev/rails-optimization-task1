# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: ruby-prof(CallTree)

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Прогонять большой объем невозможно из-за времени выполнения, поэтому создал промежуточный файл data_medium.txt c 2300 строк, чтоб можно было понять масштабы улучшений

Вот как я построил `feedback_loop`:
- проверить скорость выполнения с помощью ruby-prof flat
- поиск главной точки роста
- изменение кода

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался benchmark, ruby-prof

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- ruby-prof flat показал, что <Class::Date>#parse занимает больше всего времени
- не очень понятен смысл вызова метода iso8601 на датах такого типа '2016-09-01', поэтому можно убрать его и Date.parse
- время выполнения уменьшилось с 2.734742s до 0.839671
- главная точка роста изменилась

### Ваша находка №2
- ruby-prof calltree показал, что map внутри Object#collect_stats_from_users занимает больше всего времени
- переименовал методы, использующие map, вывел 4 наиболее используемых

    - `{ 'browsers' => user.sessions.map {|s| s['browser']}.map {|b| b.upcase}.sort.join(', ') }` занимал 21.4%, если вызывать upcase сразу, а не в отдельном map, то станет 18.89%
    
    - `{ 'longestSession' => user.sessions.map {|s| s['time']}.map {|t| t.to_i}.max.to_s + ' min.' }` занимал 17.90%, по тому же принципу можно вызывать `to_i` на `s['time']`, сокращаем до 14.17

    - `{ 'usedIE' => user.sessions.map{|s| s['browser']}.any? { |b| b.upcase =~ /INTERNET EXPLORER/ } }` 10.60%, upcase делать необязательно для поиска и можно заменить на start_with?, получается 8.88

    - `{ 'totalTime' => user.sessions.map {|s| s['time']}.map {|t| t.to_i}.sum.to_s + ' min.' }` 19.11%, вызывать `t.to_i` на `s['time']`, падает до 15.21%

- время выполнения изменилось с 0.839671 до 0.719541
- точка роста изменилась

### Ваша находка №3
- в collect_stats_from_users теперь select больше всего занимает, использовал flat и calltree
- 
    - переделал users и sessions, чтоб второе включить в первое как массив для избавления от тяжелого селекта
    - `{ 'alwaysUsedChrome' => user.sessions.map{|s| s['browser']}.all? { |b| b.upcase =~ /CHROME/ } }` убрал upcase и regex, упало с 2.90% до 2.09%
- Время выполнения уменьшилось с 0.719541 до 0.040610, collect_stats_from_users упало с 74.79% до 33.61%, части из предыдущего пункта упали до 4.64% максимум
- точка роста изменилась

### Ваша находка №4
- в collect_stats_from_users String::split является главной точкой роста
- убрал split из parse_user и parse_session, вместо этого передаю в них сразу массив
- String::split уменьшилось с 32.5% до 9.63%, время выполнения с 0.040610 до 0.034900
- точка роста та же, но как от split избавиться нет идей

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить ускорить выполнение в ~ раз и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы написал тест на minitest

