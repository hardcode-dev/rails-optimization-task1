# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и 
не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал 
использовать такую метрику: 

Время полной обработки 100_000 строк файла за 1 секунду
Процент загрузки процессора при обратке 100_000 строк файла не больше 70%

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики 
программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который 
позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: 

## Примененные технологии
Для того, чтобы найти "точки роста" для оптимизации я воспользовался:
- ruby-progressbar
- rspec-benchmark
- benchmark
- rbspy
- ruby-prof
- stackprof

Вот какие проблемы удалось найти и решить

### находка №1
- С помощью ruby-progressbar выполнил анализ асимптотики
- Выяснилось:
  - 1000 строк выполнилось за 0 секунд 
  - 10000 строк выполнилось за 2 секунды 
  - 20000 строк выполнилось за 10 секунд 
  - 30000 строк выполнилось за 23 секунды 
  - 40000 строк выполнилось за 40 секунд 
  - 50000 строк выполнилось за 72 секунды 

### находка №2
- С помощью rspec-benchmark покрыл тестами функционал
- Выставлены границы
  - 100_000 строк: не больше 2 секунд выполнения.

### находка №3
- Использован Benchmark 
- Выяснилось что отключение GC увеличивает время выполнения программы.

### находка №4
 - Использование профилировщика CPU rbspy
 - Выяснилось что дольше всех в работе 
    Формирование users_objects (85.44%)
 - Оптимизация
    - Вынес поиск по массиву хешей session из цикла users
    - Сделал группировку по user_id для данных из массива sessions
    - В цикле users получаю доступ к сессиям через церез ключ хэша
    - Заменил each для перебора users на map, чтобы не формировать отдельную переменную для массива 
 - Изменение метрики
    Формирование users_objects (0.50 %)
 - Главная точка роста устранена. 
 
 ### находка №5
  - Использование профилировщика CPU rbspy
  - Выяснилось что дольше всех в работе 
     Формирование users, sessions (53.23%)
  - Оптимизация
     - Убрал дублирование по использованию метода split
     - Передаю в методы parse_user, parse_sessions сразу массив значений cols 
  - Изменение метрики
     Формирование users, sessions (4.17%)
  - Главная точка роста устранена.
  
 ### находка №6
  - Использование профилировщика CPU ruby-prof (flat report)
  - Выяснилось что дольше всех в работе 
     36.34      0.749     0.747     0.000     0.002    50000   Array#all?
  - Оптимизация
     - Заменил all? на include? в методе unique_browsers(sessions)
  - Изменение метрики
     0.47      0.006     0.006     0.000     0.000    42305   Array#include?
  - Главная точка роста устранена.
  
### находка №7
  - Использование профилировщика CPU ruby-prof (graph report)
  - Выяснилось что дольше всех в работе 
     Выполнение метода collect_stats_from_users и его дочерний each цикл. 
     Total: 82.09% 	self: 22.10%
  - Оптимизация
     - Заменил конкатенацию на интерполяцию при формировании ключа.
     - Перенес и мемоизировал формирование fullname в класс User.
     - Перенес и мемоизировал формирование sessions_times в класс User.
     - Перенес и мемоизировал формирование browser_names в класс User.
     - Убрал дублирущие map циклы для потомков each цикла
     - Перенес генерацию всей инфомрации по пользователю в один блок.
  - Изменение метрики
     Total: 80.35% 	self: 14.33%
  - Главная точка роста была уменьшена.
  
### находка №8
  - Использование профилировщика CPU ruby-prof (CallStack report)
  - Выяснилось что дольше всех в работе 
     Выполнение метода collect_stats_from_users и его дочерний map цикл. 
     51.05% (100.00%) Array#each [1 calls, 4 total]
     30.10% (58.97%) Array#map [15390 calls, 30783 total]
     24.55% (81.56%) <Class::Date>#parse [42305 calls, 42305 total]
  - Оптимизация
     - Заменил Date.parse на Date.iso8601
     - Заменил max на sort.last
  - Изменение метрики
     26.86% (98.84%) Array#each [1 calls, 4 total]
     9.80% (36.46%) Array#map [3 calls, 12 total]
  - Главная точка роста была устранена.
  
### находка №9
  - Использование профилировщика CPU stackprof (CallStack report)
  - Выяснилось что дольше всех в работе 
     Выполнение метода unique_browsers  
     95  (14.8%)          95  (14.8%)     Object#unique_browsers
  - Оптимизация
     - Заменил each цикл на map 
     - Отказался от поиска нового браузера в массиве уникальных браузеров
     - Использовал метод uniq на массиве названий браузеров 
  - Изменение метрики
     8   (1.5%)           8   (1.5%)     Object#unique_browsers
  - Главная точка роста была устранена.
  
### находка №10
  - Использование fasterer гема
  - Выяснилось  
      - Block.call медленнее yield
  - Оптимизация
    - Заменил Block.call на yield
    - Заменил дублирующие map циклы. 
  - Изменение метрики
      На полном объеме данных уменьшение времени выполнения с 1.24 минуты до 1.20 минуты. 
  - Fasterer больше не ругается на неоптимизированный код.
  
### находка №11
  - Использование профилировщика CPU ruby-prof (flat report)
    - Выяснилось что дольше всех в работе 
       21.53     27.875    24.031     0.000     3.845  2750940   <Class::Date>#iso8601
  - Оптимизация
       - Перенес формирование даты в парсинг сессий
       - Заменил sort на sort_by в формировании дат для отчета 
  - Изменение метрики
       4.98      0.000     0.000     0.000     0.000       15   <Class::Date>#iso8601
  - Главная точка роста устранена.

### находка №12
  - Использование профилировщика CPU ruby-prof (callstack report)
    - Выяснилось что дольше всех в работе 
       Метод parse_session (35.17%)
  - Оптимизация
       - Избавился от regexp при поиске users и sessions строк
       - Заменил строки в формируемом хэше на symbol
       - Перенес парсинг даты сессий в класс User.  
  - Изменение метрики
       Метод parse_session (1.04%)
  - Главная точка роста устранена.
  
### находка №13
  - Использование профилировщика CPU ruby-prof (flat report)
    - Выяснилось что дольше всех в работе 
       Метод each при парсинге строк файла (12.61%)
  - Оптимизация
       - Заменил each на while
  - Изменение метрики
       Упоминание while отстувует в отчете. 
  - Главная точка роста устранена.

### находка №14
  - Использование профилировщика CPU ruby-prof (flat report)
    - Выяснилось что дольше всех в работе 
       Метод Regexp#match (8.15%)
  - Оптимизация
       - Перенос проверки браузера сессии в метод формирования сессии. 
       - Замена =~ на метод start_with?
  - Изменение метрики
       Метод Regexp#match (4.76%)  
  - Главная точка роста устранена.
  
### находка №15
  - Использование профилировщика CPU ruby-prof (все виды отчетов)
    - Выяснилось что дольше всех в работе 
       Метод each (21.78%). В проекте остался один each, который формирует данные для конечного отчета.
  - Оптимизация
       - Переделал each метод на while. Вынес формирование информации по сессиям пользователей в один цикл. 
       - Удалил преобразование даты с помощью Date, т.к. дата поступает корректно и ее парсинг не требуется. 
       - Удалил повторное создание уникальных имен браузеров сессий
       - Вынес подсчет количетва users, session в метод парсинга строк.
       - Вынес формирование имен браузеров в метод парсинга строк.
       - Вынес группировку сессий по пользователям в метод парсинга строк.
  - Изменение метрики
       Метод each\while больше не фигурирует в отчетах
       Выполнение программы снизилось до примерно 50 секунд на полном объеме.  
  - Главная точка роста устранена.
  
### находка №16
  - Использование профилировщика CPU ruby-prof (все виды отчетов)
    - Выяснилось что 4% Выполняется создание объекта User  
  - Оптимизация
       Удалил класс User. Оставил массив users и итерацию по нему.  
  - Изменение метрики
       Устранена точка роста.
       Время выполнения на полном объеме данных снизилось до 47 секунд.

### находка №17
  - Использование профилировщика CPU ruby-prof (все виды отчетов)
    - Выяснилось что 4.39% Выполняется upcase для имени браузера.   
  - Оптимизация
       Заменил upcase на upcase! что бы не создавалась новая строка.
  - Изменение метрики
       Выполнение преобразования стало занимать 3.45%
  - Точка роста устранена. 
  
### находка №18
  - Использование профилировщика CPU ruby-prof (все виды отчетов)
    - Выяснилось что 21% времени выполнения занимает преобразование в json и запись в файл.    
  - Оптимизация
      Установил гем OJ 
  - Изменение метрики
       Устранена точка роста.
       Время выполнения на полном объеме данных снизилось до 36 секунд.
  - Точка роста устранена. 

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Выполнение программы снизилось до ~30 секунд на полном объеме данных.
Удалось улучшить метрику системы: 
 - с 72 секунды при 50_000 строк
 - до 0.15 секнды при 50_000 строк 
 
 - с больше 100 секунд при 100_000 строк
 - до 0.34 секнды при 100_000 строк 
  
При 100_000 строк выполнение программы занимает меньше 1 секунды.  

Уложиться в заданный бюджет обозначенный в ДЗ получсилось.
Парсинг полного объема данных занимает ~30 секунд.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях 
программы были реализованы тесты, предполагающие, что выполнение 100_000 строк не будет превышать 2-х секунд. 

