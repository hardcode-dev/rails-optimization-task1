# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было 
понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я буду использовать
такую метрику, как **время обработки файла**. 

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы 
при оптимизации.

## Feedback-Loop и моя подготовка к нему
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне 
получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Перед началом цикла оптимизации решил подготовить весь проект к какому-то более-менее приличному виду, который мне позволит в комфорте проводить оптимизацию,
ну и естественно подумал, что оптимизированным решением было бы посмотреть статьи на тему профайлинга и тех инструментов, 
которые я буду использовать как для поиска хороших практик, так и для может быть дополнительной инфы, кроме той, которую 
рассказывал сам Алексей на курсе. 

Прочитал документации библиотек, представленных в дашборде во вкладке CPU. Очень заинтересовался репозиторием fast-ruby.
Немножко порыскав во всемирной паутине нашел интересную статью на хабре https://habr.com/ru/post/561258/, где в целом задача 
примерно такая же, как у меня сейчас, что безусловно мне пригодилось как в подготовке среды, так и к общей истории с оптимизацией.

Далее последовали следующие шаги подготовки проекта к циклам оптимизации и последующей публикации этого дз для других людей:
1. Так как мы используем зависимости для профилирования, то создаю Gemfile с указанием версий как гемов, так и Ruby.
2. Создаю .gitignore
3. Дальше потихоньку начинаю погружаться в требования задания, вспоминаю, что очень важным фактором для оптимизации является проведение асимптотического анализа, а значит понадобится несколько исходных файлов текста, которые позволят найти асимптоту. Для всего этого нам понадобится дополнительный аргумент **filename** к методу work.
4. После беглого осмотра файла task-1.rb заметил наличие тестов прямо в этом же файле. Естественно вынес их в другой файл test/task_1_test.rb
5. Так как мы хотим в начале найти асимптоту, то решил создать 10 файлов с шагом в 2000 строк.

``` 
# generate data
lines = [2000, 4000, 6000, 8000, 10000, 12000, 14000, 16000, 18000, 20000]

lines.each do |line|
head -n #{line} data/data_large.txt > data/data-#{line}-lines.txt
end
```
6. Создаю файл `profilers/benchmark_data.rb` для подсчета времени обработки исходников с использованием метода `Benchmark.realtime`. Получаю результаты:

``` 
$ ruby profilers/benchmark_data.rb
   2000 Completed in 0.082 ms
   4000 Completed in 0.271 ms
   6000 Completed in 0.582 ms
   8000 Completed in 1.007 ms
   10000 Completed in 1.67 ms
   12000 Completed in 2.389 ms
   14000 Completed in 3.209 ms
   16000 Completed in 4.452 ms
   18000 Completed in 5.424 ms
   20000 Completed in 6.58 ms
``` 
7. C помощью plotly.com построил график с этими значениями. Получилось что-то похожее на `1.6 * x^2`, то есть линейность отсутствует и при большем количестве строк во входных данных есть серьезные обоснования таки не дождаться долгожданного списка с результатами..
   ![alt text](https://i.imgur.com/KEf67gj.png)
8. Добавляю параметр для метода work `disable_gc` со значением `true` по умолчанию, чтобы уменьшить разброс времени выполнения
9. Теперь пробую написать небольшой тестик для того, чтобы недопустить более худшего времени выполнения и уже наконец-то приступать к самой оптимизации. Лезу в гитхаб `rspec-benchmark` и из общих практик составляю вроде что-то рабочее. В качестве эталона для теста беру 8000 строк с не более 1.5 секунды выполнения.

```      
expect {
         work('data/data_8000.txt')
       }.to perform_under(1500).ms.warmup(2).times.sample(5).times
```
10. Изначально планировал во всю использовать встроенный в RubyMine rbspy, но по какой-то причине он у меня отвалился и кнопка активации была неактивная, при том, что через консоль все отлично вызывалось. Повозившись еще немного решил все-таки вернуться к `ruby-prof` с тремя разными типами данных. Плюс дополнительно для визуализации использовал `flamegraph`
11. Ну и последним пунктом перед циклом настраиваю себе в IDE две конфигурации: под запуск тестов, и под профилировщики, что позволит очень быстро проходить итерации.

## Вникаем в детали системы, чтобы найти главные точки роста
### Ваша находка №1
- `Ruby prof` довольно таки прямо сказал, что проблема в `Array#select`, берущий на себя 89% времени обработки. 
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

### Ваша находка №2
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

### Ваша находка №X
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*

