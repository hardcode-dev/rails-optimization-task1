# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы, я придумал использовать такую метрику: время выполнения метода work в секундах для одного и того же набора входных данных.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за время менее 5 секунд, выделенное на запуск и выполнение специально написанных тестов (на выборке 10000 записей), которые в свою очередь проверяют соответствие выбранной метрики и бюджета.

Вот как я построил `feedback_loop`:

Фреймворк оптимизации подразумевает наличие последовательности Profile – Modify – Test – Benchmark – Commit/Revert для проверки гипотез по вариантам улучшений. Т.к. мы не можем запустить нашу программу на исходном большом целевом файле с данными (слишком долгое время обработки), для создания быстрого feedback loop потребовался еще предварительный шаг, где предоставленные данные разбиваются на меньшие объемы, и уже на основе них строятся тесты для фиксирования текущей производительности как отправной точки. Кроме этого было необходимо расширить метод work для передачи опционального параметра с названием файла. По умолчанию метод бы запускался с прежним существующим файлом data.txt, а для новых тестов можно было бы передавать названия файлов с бОльшими выборками. Самая первая итерация представляла из себя написание тестов производительности (время выполнения программы, число итераций в единицу времени). В данном случае это можно отнести к шагу Profile & Test & Benchmark. Полученные при первом запуске значения бенчмарка мы можем записать в цели теста для исключения регрессий на последующих итерациях. Теперь, получив отправное время выполнения программы на разных небольших наборах данных, мы можем оценить асимптотику, дописав еще один тест для ее оценки. Она оказалась линейной при запуске программы для 100 первых строк, затем 1000 и затем 10000 строк.
С этого момента наш feedback loop создан, и мы можем переходить к профилированию и изменению кода, после чего запускать уже написанные тесты для сравнения результатов с отправным шагом (или шагом предыдущей итерации).
Код без изменений показал следующую производительность для Ruby 2.7.7 на небольших размерах данных: для 100 первых строк из data_large.txt время выполнения составило около 0.7мс, число итераций за 1 секунду не менее 1.54k.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался ruby-prof

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- какой отчёт показал главную точку роста:
  * ruby-prof в режиме Flat с профилем на 10.000 строк указал на большее время проведенное внутри метода Array#select: 86.59% времени при 1536 вызовах. Это и есть наша первая точка роста. На втором месте был Array#all? с 4,36% времени и 10.000 вызовами. На третьем месте был Array#each с 4,3% времени и 10 вызовами
- как вы решили её оптимизировать:
  * число вызовов говорит нам о том, что мы много раз обходим один и тот же массив сессий, чтобы найти в нем те или иные данные, соответствующие пользователям. Мы можем переписать этот цикл так, чтобы мы не начинали обход всех сессий заново по каждому пользователю, а прошли весь массив один раз, и уже внутри этого обхода сопостовляли текущую сессию с тем или иным пользователем, обновляя статистику для него
- как изменилась метрика:
  * время выполнения для 10.000 строк сократилось с 0.72 сек до 0.1 сек
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  * да, точка роста перестала отображаться среди первых 6 результатов. Теперь на первое место вывел Array#each с 33.07% и 11 вызовами. На втором месте Array#all? с 31.95% и 10.000 вызовами

### Ваша находка №2
- какой отчёт показал главную точку роста:
  * из-за наличия нескольких вызовов метода each необходимо было воспользоваться другим режимом вывода информации профилировщиком, например в виде HTML таблицы вызовов и зависимостей методов (ruby-prof GraphHtmlPrinter). Больше всего вызовов each происходило внутри метода collect_stats_from_users. Это станет нашей второй точкой роста.
- как вы решили её оптимизировать
  * как мы видим, число вызовов each внутри этого метода корреллирует напрямую с множественными вызовами самой collect_stats_from_users. Для сбора разной статистики по разным категориям мы каждый раз снова вызываем метод и снова обходим всех имеющихся пользователей, чтобы найти соответствия. Придется провести рефакторинг, ведь всю информацию можно получить из данных о сессиях для каждого пользователя за один раз. Стоит объединить все отдельные вызываемые блоки в один большой, который мы и передадим в collect_stats_from_users для выполнения над каждым пользователем
- как изменилась метрика
  * время выполнения для 10.000 строк осталось прежним
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  * да, вызовы each сместились на второе место, вперед вышел метод all? на 82 строке

### Ваша находка №3
- какой отчёт показал главную точку роста
  * перезапуск профилировщика после работы со второй точкой роста в предыдущем пункте вывел на первое место вызовы all? с 33,09% времени и 10.000 обращениями. Речь идет о том методе, который помещен внутрь другого цикла (поиск уникальных браузеров)
- как вы решили её оптимизировать
  * можно отбросить многократную проверку наличия текущего найденного браузера в списке уже отмеченных как уникальные, заменив этот цикл на map, а затем убрав из него дубликаты методом uniq. Несколькими строчками ниже мы составляем список всех используемых браузеров с той же повторяющейся логикой, поэтому имеет смысл одновременно на этом же шаге провести небольшой рефакторинг, отдельно составив список уникальных браузеров, а затем применив к этому списку операции подсчета записей, а затем отдельно приведение к верхнему регистру с сортировкой и конвертацием в строку. Так мы не допустим дублирования одного и того же кода с одинаковым смыслом и предназначением
- как изменилась метрика
  * время выполнения для 10.000 строк снизилось до 0.07 сек
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  * да, вызовы all? опустили до процента. Впереди теперь collect_stats_from_users с 45,81% (total, а self 0), после него each (self 44,5%) и map (33,8% total)

### Ваша находка №4
- какой отчёт показал главную точку роста
  * как мы видим из перезапуска того же профилировщика GraphHtmlPrinter после выполнения предыдущего шага оптимизации, имеет смысл исследовать длительные вызовы each, занимающие 95.46% времени выполнения (без дочерних вызовов 44.42%). Но вызовов each у нас много, поэтому стоит запустить CallStackPrinter, чтобы посмотреть стек вызовов, какой метод по времени использования вызывает следующий. Главной точкой роста оказывается each, вызываемый напрямую в теле программы, т.е. file_lines.each. Самым весомым дочерним вызовом является обращение к split. Это станет следующей точкой роста
- как вы решили её оптимизировать
  * сократить число вызовов split, достаточно один раз разбивать каждую строку на столбцы. Попутно можно отрефакторить способ разделения и помещения строк в массивы пользователей и сессий соответственно
- как изменилась метрика
  * время выполнения для 10.000 строк снизилось до 0.04 сек
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  * да, теперь основное ресурсоемкое место - дочерние для collect_stats_from_users вызовы map (52.21%)

### Ваша находка №5
- какой отчёт показал главную точку роста
  * в этот раз я использовал отчет CallTreePrinter, чтобы определить, что на текущем этапе бОльшую часть ресурсов стали задействовать вызовы map, а точнее вызов Date.parse внутри одних из них
- как вы решили её оптимизировать
  * преобразование строки с датой в объект Дата и обратно к строке того же формата избыточно, мы можем напрямую работать с первоначальной строкой в сессии
- как изменилась метрика
  * время выполнения для 10.000 строк снизилось до 0.02 сек
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  * да и нет: основное ресурсоемкое место - дочерние для collect_stats_from_users вызовы map (27.35%), но теперь уже речь об их общем количестве и повторяемых операциях преобразований к целым числам и заглавным символам

### Ваша находка №6
- какой отчёт показал главную точку роста
  * запускаю разные отчеты, но в сумме наиболее наглядным является снова CallTreePrinter: видно и вложенность, и ресурсоемкость конкретных вызовов. Как и стало заметно в конце прошлой итерации, точка роста сместилась к вызовам map, их количеству и применению друг за другом
- как вы решили её оптимизировать
  * в этот раз пришлось совершить больше всего изменений, тщательно отследив последовательность и смысл выполнения изменений и сбора статистики из сессий. Я постарался вынести те операции, которые можно совершить однократно, в метод парсинга сессий: это приведение времени к целому числу и приведение строки названия браузера к заглавному формату. В итоговом методе сбора статистики по сессиям для пользователя я тоже уменьшил число обходов сессий, чтобы за одну итерацию произвести как можно больше действий сразу.
- как изменилась метрика
  * время выполнения для 10.000 строк осталось равным 0.02 сек
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  * да, map сместились в конец. Следующими шагами потенциально являются методы split и to_json.

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*

