# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: время обработки файла в секундах

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 15 секунд

Вот как я построил `feedback_loop`:

1. Профилирование(поиск точки роста ruby-prof )
2. Изменение кода
3. Тесты
4. Постоение отчета 

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался:

- benchmark(построение отчета асимптотики)
- ruby-prof 

Вот какие проблемы удалось найти и решить
## Асимптотика
| Объём | Время(benchmark) |
| ------ | ------ |
| 1500 | 0.054 |
| 3000 | 0.212 |
| 6000 | 0.874 |
| 12000 | 4.235  |
| ... | ... |
| N | ... |

Сложность O(N^2)

Кол-во строк в файле: 3250940

### Ваша находка №1
- Array#select (80%) 

```sessions.select { |session| session['user_id'] == user['id'] }```
- Предварительно сгруппировать сессии по user_id
```
user_sessions = sessions.group_by { |session| session['user_id'] }
users.each do |user|
  users_objects << User.new(attributes: user, sessions: user_sessions[user['id']])
end
``` 
 
- | Объём | Время |
  | ------ | ------ |
  | 1500 | 0.034 |
  | 3000 | 0.06 |
  | 6000 | 0.118 |
  | 12000 | 0.303 |
  | ... | ... |
  |  N  | ... |
  
  Сложность O(N)
- метрики улучшились, сложность O(N^2) => O(N)
- исправленная проблема перестала быть главной точкой роста

### Ваша находка №2
- Array#all?(33%), подсчёт количества уникальных браузеров

```
uniqueBrowsers = []
  sessions.each do |session|
    browser = session['browser']
    uniqueBrowsers += [browser] if uniqueBrowsers.all? { |b| b != browser }
  end
```
- Переписал на:
```
sessions.map { |s| s['browser'] }.uniq
``` 

- | Объём | Время |
    | ------ | ------ |
  | 1500 | 0.026 |
  | 3000 | 0.045 |
  | 6000 | 0.092 |
  | 12000 | 0.258 |
  | ... | ... |
  |  N  | ... |
  
  Сложность O(N)
- метрики немного улучшились
- исправленная проблема перестала быть главной точкой роста

### Ваша находка №3
- Date#parse(18.35%)

```
user.sessions.map{|s| s['date']}.map {|d| Date.parse(d)}.sort.reverse.map { |d| d.iso8601 }
```
- Убрал парсинг даты
```
user.sessions.map{|s| s['date']}.sort.reverse
``` 

- | Объём | Время |
  | ------ | ------ |
  | 1500 | 0.019 |
  | 3000 | 0.034 |
  | 6000 | 0.073 |
  | 12000 | 0.195 |
  | ... | ... |
  |  N  | ... |
  
  Сложность O(N)
- метрики немного улучшились
- исправленная проблема перестала быть главной точкой роста

### Ваша находка №4
- Array#each(52.90%), парсинг данных из файла

```
file_lines.each do |line|
    cols = line.split(',')
    users = users + [parse_user(line)] if cols[0] == 'user'
    sessions = sessions + [parse_session(line)] if cols[0] == 'session'
  end
```
- Убрал многократный вызов метода split, изменил метод записи в массив 
```
file_lines.each do |line|
    cols = line.split(',')
    users << parse_user(cols) if cols[0] == 'user'
    sessions << parse_session(cols) if cols[0] == 'session'
  end
``` 

- | Объём | Время |
    | ------ | ------ |
  | 1500 | 0.017 |
  | 3000 | 0.024 |
  | 6000 | 0.049 |
  | 12000 | 0.089 |
  | ... | ... |
  |  N  | ... |
  
  Сложность O(N)
- метрики улучшились, O(N)
- исправленная проблема перестала быть главной точкой роста

### Ваша находка №5
- Object#collect_stats_from_users(60.67%), 7 раз вызов метода
- Убрал многократный вызов метода split, изменил метод записи в массив
- | Объём | Время |
  | ------ | ------ |
  | 1500 | 0.016 |
  | 3000 | 0.021 |
  | 6000 | 0.040 |
  | 12000 | 0.082 |
  | ... | ... |
  |  N  | ... |
  
  Сложность O(N)
- метрики немного улучшились
- исправленная проблема перестала быть главной точкой роста

### Ваша находка №6
- Array#map 26.49% [8361 calls, 8364 total]

```
   {
      'sessionsCount' => user.sessions.count,
      'totalTime' => user.sessions.map {|s| s['time']}.map {|t| t.to_i}.sum.to_s + ' min.',
      'longestSession' => user.sessions.map {|s| s['time']}.map {|t| t.to_i}.max.to_s + ' min.',
      'browsers' => user.sessions.map {|s| s['browser']}.map {|b| b.upcase}.sort.join(', '),
      'usedIE' => user.sessions.map{|s| s['browser']}.any? { |b| b.upcase =~ /INTERNET EXPLORER/ },
      'alwaysUsedChrome' => user.sessions.map{|s| s['browser']}.all? { |b| b.upcase =~ /CHROME/ },
      'dates' => user.sessions.map{|s| s['date']}.sort.reverse
    }
```  
- Убрал многократный вызов метода map

```
file_lines.each do |line|
    cols = line.split(',')
    users << parse_user(cols) if cols[0] == 'user'
    sessions << parse_session(cols) if cols[0] == 'session'
  end
```  
- | Объём | Время |
    | ------ | ------ |
  | 1500 | 0.014 |
  | 3000 | 0.019 |
  | 6000 | 0.041 |
  | 12000 | 0.064 |
  | ... | ... |
  |  N  | ... |
  
  Сложность O(N)
- метрики улучшились
- исправленная проблема перестала быть главной точкой роста

### Ваша находка №7
- String#upcase 3% , вызов в разных местах
- Убрал многократный вызов метода
- | Объём | Время |
      | ------ | ------ |
  | 1500 | 0.013 |
  | 3000 | 0.018 |
  | 6000 | 0.029 |
  | 12000 | 0.060 |
  | ... | ... |
  |  N  | ... |
  
  Сложность O(N)
- метрики улучшились
- исправленная проблема перестала быть главной точкой роста

### Ваша находка №8
- Hash#to_json 5.36% 
- Заменил json на oj
- | Объём | Время |
        | ------ | ------ |
  | 1500 | 0.012 |
  | 3000 | 0.014 |
  | 6000 | 0.024 |
  | 12000 | 0.052 |
  | ... | ... |
  |  N  | ... |
  
  Сложность O(N)
- метрики улучшились
- исправленная проблема перестала быть главной точкой роста

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы до 26секунд и уложиться в заданный бюджет.
(3250940 / 1500) * 0.12 = ~26,00сек.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы были написыны тесты:

```
RSpec.shared_examples 'check speed' do |size, time|
  context "when size == #{size}" do
    let(:size) { size }

    it 'works under 0.5 s' do
      expect { work }.to perform_under(time)
    end
  end
end

context 'check execution speed' do
  it_behaves_like 'check speed', 1500, 0.15
  it_behaves_like 'check speed', 3000, 0.3
  it_behaves_like 'check speed', 6000, 0.6
  it_behaves_like 'check speed', 12000, 0.12
end
```
