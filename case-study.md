# Case Study Оптимизации

> Дисклеймер:   
> Я начал менять приложенный отчет но мне это быстро разонравилось. Очень формальный язык и не сильно заметно где мои вставки а где "рыба". Да и вам вряд ли интересно по пятому кругу читать один и тот же документ. Поэтому я все удалил и просто написал в свободной форме как решал задачу.  
>
> Сразу прошу прощения если нужен был именно формальный отчет. Но кмк цель выполняется и в этом документе.

### Общий лог оптимизации

#### Первые шаги

- Запустил программу и убедился что она работает
- Небольшой рефакторинг чтобы было удобнее запускать и менять код
- Нарезал 4 файла на несколько тысяч строк (4к - 8к - 16к - 32к)
- Запустил Benchmark.ips на каждом, посмотрел как падает производительность.
- Выстроил feedback loop
  - программа запускается на одном и том же файле
  - Benchmark.realtime выдает в консоль сколько секунд это заняло
  - сразу же генерируются отчеты профилировщика которые можно посмотреть
  - Каждый раз запускается тест и проверяет что программа работает корректно
- Теперь можно быстро запускать программу и видеть результат.
- Метрика которую я буду улучшать -- время работы программы и "сбалансированность" методов в отчетах

#### Первая оптимизация

- Первый запуск, посмотрел flat отчет
- Показался неудобным, сразу перешел на html и callstack отчеты ruby-prof
- После прогона видно что метод array#select занимает 83% времени
- начал оптимизировать
  - переписал на использование хеша а не поиска по массиву. для этого вместе с массивом параллельно еще собирается хеш с сессиями каждого юзера
  - проверил что сборка доп. хеша не просаживает производительность (метрика 1.169 -> 1.154 секунд)
  - все нормально, можно убирать select и подставлять туда выбор по ключу
  - метрика стала 0.248, почти в пять раз быстрее
  
  
#### Вторая оптимизация

- перезапустил программу, увидел что теперь четверть времени уходит на array.all? на 95 строчке
- начал оптимизировать
  - опять использовал хеш вместо массива. (когда парсим файл, браузеры добавляются в хеш где ключ = имя браузера, потом просто берем все ключи хеша и получаем список уникальных)
  - метод полностью пропал из списка вызовов, то есть занимает меньше 1% теперь
  - метрика упала до 0.202
  - ассимптота не измениалсь, тесты зеленые. Можно переходить к следующей точке
  
#### Третья оптимизация

- отчеты переставил быть показательным. Я решил еще выносить код в методы с нормальными именами чтобы видеть все проблемы.
Для этого я обернул каждый вызов collect_stats_from_users в свой метод и стал смотреть отчеты
- 55% уходит на то чтобы собрать хеш, из которого потом собирается отчет
- вижу что string.split дергается в несколько раз больше чем строк в файле
- по отчетам не видно что это точка роста, но я знаю как это быстро пофиксить и решаю потратить 5 минут
  - вынес split на уровень выше и он дергается один раз для строчки, а в остальные методы передается сразу массив полей 
  - После оптимизации метрика подскочила до 0.097 (ускорение в три раза)
  - оказалось что этот сплит занимал прилично времени, но я пофиксил его вслепую. Повезло
- производительность сбора инфы из файла меня устраивает, перехожу к коду формированию отчета

#### Четвертая оптимизация

- вижу что метод который пишет даты юзера занимает 43% времени и большая часть ресурсов тратится на Date.parse
- начал разбираться и увидел что даты уже в нужном формате, поэтому парсить и переводить их в iso8601 как бы и не нужно
- удаляю ненужные вызовы
  - _примечание: в реальном проекте я так конечно никогда бы не сделал, потому что то что даты сейчас в нужном формате это чистое везеение, и я не хочу чтобы завтра этот формат изменился и у нас сломался отчет. Но тк задание тестовое и цель не в оптимизации дат а в общем фреймворке, я решил что эта часть не критчина сейча_
- метод ускорился и стал занимать ± как остальные семь
                                        
### мысли куда двигаться дальше

я вижу по отчету что сбор инфы из файла занимает 35% времени (не узкое место)


![](https://sun9-24.userapi.com/6jZq8Pl1HS3v7SdNZF18-VCJRzc4424zy2I0cg/qvKaldx8-SY.jpg)

65% занимает запись отчета.  
Но все методы в этой записи занимают ± одинаковое время поэтому нет смысла улучшать какой-то один.  

Следовательно пора глобально исправлять асимптотику
                      
#### Исправление асимптотики (пятая оптимизация)                                    
- надо понять где асимптотика проваливается
  - решаю проверить обе части (чтение и формирование отчета) изолированно
  - отключаю генерацию отчета и запускаю чисто чтение на полном файле
  - прошло за 15 секунд, значит тут проблем нет.
  - перехожу к генерированию
    - из кода быстро понятно что там куча проблем
    - переписываю код оптимальнее, создаю метод `generate_single_user_info` который не будет для одного юзера много раз перебирать одни и те же сессии
    - тесты проходит, по смыслу сложность упала.
    
#### Запуск на полном файле и шестая оптимизация
- теперь по ощущениям оптимизация завершена. Я знаю что сбор данных из файла занимает 15 секунд и это 35% времени выполнения, то есть полный отчет соберется за 45 секунд. Меня это устраивает и я запускаю отчет ан полном файле
- отчет висит без движения
- удивлюясь, решаю посмотреть в динамике на каком этапе висит отчет
  - вижу что очень долго висит метод который собирает объекты пользователей из данных но по отчету профилировщика непонятно, в чем там проблема
  - решаю использовать старый добрый console.log driven development
  - расставляю puts там и тут чтобы видеть в каком месте программа висит
  - программа проходит за 35 секунд
  - WTF?!
  - смотрю изменения в коде и понимаю что рефакторинг одной строчки все пофиксил
    - речь о замене `users = users + [user]` на привычную `users << user`
    - оказывается в ней было много тормозов но я переписал ее ради читаемости на автомате и даже этого не понял
    - ну, зато у нас есть работающая программа
- Репорт собирается из полного файла за пристойное время
- В принципе считаю задачу решенной

#### Седьмая оптимизация

- тк я по сути попал в бюджет то решаю что оптимизация завершена и профайлер дальше не использую
- решаю заменить строковые ключи в хешах на символы (с целью оптимизации)
- отчет стал собираться еще на несколько секунд быстрее 
  - в среднем за 29-35 секунд стабильно

                    
#### Тесты, составление данного документа.

- сабж
- тест на сложность алгоритма сходу написать не удалось потому что для этого бы пришлось рефакторит код (см комментарий в файле со спеками) 