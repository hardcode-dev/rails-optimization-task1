# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: *тут ваша метрика*

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`:

С помощью команды `wc -l data_large.txt` посчитал количество строк в файле `data_large.txt` - 3250940.

Далее с помощью команды `head -n N data_large.txt > dataN.txt` (где N - количество строк) создал несколько более мелких файлов для 1000, 2000, 4000, 8000 строк, а так же файлы с 1%, 10% и 50% строк, для более быстрого профилирования и определения зависимости скорости выполнения от объема входных данных.

`rspec-performance` показал, что зависимость квадратичная.

Для удобства чтения отчетов я выделил формирования каждой части отчета в отдельный метод

В `feedback-loop` я использовал 2 вида тестов:

- `Benchmark.realtime` для подсчета общего времени выполнения на выбранном объеме данных
- `Rspec::Benchmark` с матчерами `perform_under`, `warmup(2).times` и `sample(3).times` для защиты от деградации после внесения изменений

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался: 
- `RubyProf` с `GraphHtmlPrinter` для построения "сэндвич" отчетов, на которых видно кем и сколько раз вызываются самые времязатратные части кода
- `StackProf` для формирования наглядных флейм-графов с возможностью видеть временную зависимость выполнения каждого метода

Вот какие проблемы удалось найти и решить

### Находка №1
- отчет `StackProf` показал, что главной точкой роста на первом этапе был метод `.select` в `generate_users_objects`. На `1% данных` он занимал `13.5 сек`, что составляло `92%` от общего времени работы программы.
- чтобы не перебирать каждый раз весь объем данных при сборе информации о сессиях для каждого пользователя, на этапе чтения данных из файла собираем сессии как хэш, где ключом будет `user_#{id пользователя}`, а значением массив хэшей для каждой сессии
- такой подход позволил значительно сократить время работы до `299мс` и позволило запускать тесты с `50% объемом данных`
- в результате рефакторинга временная шкала производительности в этой части программы перестала быть заметной на графе

### Находка №2
- отчет `StackProf` показал, что на данном этапе большее время занимает подсчет количества уникальных брацзеров. `StackProf` показывал время выполнения `5.9` сек от общих `19 сек` на `50% объеме данных`. Это и есть следующая точка роста
- вместо перебора сессий методом `each` и сравнением каждого значения я решил воспользоваться методом `uniq` для массива всех сессий и подсчитать их количество методом `count`
- в результате время работы `unique_browsers_count` снизилось до `1.06 сек`, а общее время составило `14.99 сек`
- теперь в отчете `StackProf` при выборе сортировки `Left Heavy` картина изменилась и можно двигаться дальше

### Находка №3
- отчет `StackProf` теперь показывал следующую точку роста - `users_sessions_dates` с результатом `4.7 сек` на `50% данных`
- замена `Date.parse` на `Date.strptime` позволила сократить время выполнения вдвое - до `2.32 сек`
- общее время работы на `50% данных` сократилось до `12.22 сек`
- отчет `StackProf` показал, что метрика была улучшена и выявил новую точку для улучшения

### На данном этапе можно переходить на полный обхем данных из файла `data_large.txt` (время выполнения `33.6 сек`)

### Находка №4
- из отчета `StackProf` стало видно, что следующим узким местом является множественные вызовы метода `collect_stats_from_users`
- было решено выделить два метода - `generate_users_report` и `generate_sessions_report` для формирования отчета с меньшим количеством итераций
- общее время работы на `100% данных` сократилось с `33.6` до `20.5 сек`
- отчет `StackProf` показал что мы укладываемся в назначенный бюджет

### Rubocop

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Несмотря на то, что требуемый результат был достигнут, время выполнения программы укладывалось в 30-секундный бюджет и тест показывал, что отчет формируется правильно, оставался еще `Rubocop`

При вынесении блоков кода, на которые ругался `rubocop` в отдельные методы, было внесено еще несколько улучшений:
- убрал лишние `.split` из `parse_session` и `parse_user`, в результате чего время работы сократилось до `18.1 сек`
- так как формирование отчета подразумевает определенный формат записей в файле с исходными даннами, а даты в этой файле уже имеют требуемый формат, парсинг даты показался лишним и была оставлена только сортировка в обратном порядке. Это позволило выиграть еще несколько секунд и `rspec-benchmark` показывал итоговое время `15 sec (± 394 ms)`

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы использовался тест `Rspec::Benchmark` с матчерами `perform_under` (время корректировалось каждый раз, когда был достигнут определенный результат), `warmup(2).times` и `sample(3).times` 

